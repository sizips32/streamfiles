import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV
)
from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import (
    mean_squared_error,
    r2_score,
    accuracy_score,
    mean_absolute_error,
    roc_auc_score,
    confusion_matrix,
    precision_score,
    recall_score,
    f1_score,
    roc_curve,
    auc
)
import plotly.graph_objects as go
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, BatchNormalization
from tensorflow.keras.optimizers import Adam
from xgboost import XGBRegressor, XGBClassifier
try:
    from lightgbm import LGBMRegressor, LGBMClassifier
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    st.warning("LightGBMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install lightgbm")
import plotly.express as px
import time
import sys
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.utils.class_weight import compute_class_weight
import lightgbm as lgb

# ì „ì—­ ë³€ìˆ˜ ì„¤ì •
XGBOOST_AVAILABLE = False

# XGBoost ê°€ìš©ì„± í™•ì¸
try:
    from xgboost import XGBClassifier
    XGBOOST_AVAILABLE = True
except ImportError:
    st.warning("XGBoostë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install xgboost")

# LightGBM ê°€ìš©ì„± í™•ì¸
try:
    from lightgbm import LGBMClassifier
    LIGHTGBM_AVAILABLE = True
except ImportError:
    st.warning("LightGBMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install lightgbm")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Financial Machine Learning App", layout="wide")
st.title("Financial Machine Learning Analysis")

# ëª¨ë¸ ì„¤ëª… ì„¹ì…˜
with st.expander("ğŸ“š ëª¨ë¸ ì„¤ëª… ë° íŒŒë¼ë¯¸í„° ê°€ì´ë“œ", expanded=True):
    st.markdown("""
    ### ğŸ¤– ëª¨ë¸ ì¢…ë¥˜ë³„ íŠ¹ì§•
    
    #### 1. Random Forest
    - **íŠ¹ì§•**: ì—¬ëŸ¬ ê°œì˜ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ì•™ìƒë¸”í•˜ëŠ” ëª¨ë¸
    - **ì¥ì **: ê³¼ì í•©ì— ê°•í•˜ê³ , íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŒ
    - **ë‹¨ì **: ëª¨ë¸ì´ ë³µì¡í•˜ê³  í•™ìŠµ/ì˜ˆì¸¡ ì‹œê°„ì´ ê¹€
    
    #### 2. ì„ í˜• íšŒê·€
    - **íŠ¹ì§•**: ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ë¥¼ ëª¨ë¸ë§
    - **ì¥ì **: í•´ì„ì´ ì‰½ê³  í•™ìŠµì´ ë¹ ë¦„
    - **ë‹¨ì **: ë¹„ì„ í˜• ê´€ê³„ë¥¼ í¬ì°©í•˜ê¸° ì–´ë ¤ì›€
    
    #### 3. LSTM
    - **íŠ¹ì§•**: ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì— íŠ¹í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸
    - **ì¥ì **: ì¥ê¸° ì˜ì¡´ì„±ì„ ì˜ í¬ì°©í•˜ê³  ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥
    - **ë‹¨ì **: ë§ì€ ë°ì´í„°ì™€ ê³„ì‚° ìì›ì´ í•„ìš”
    
    ### ğŸ“Š íŒŒë¼ë¯¸í„° ì„¤ëª…
    
    #### Random Forest íŒŒë¼ë¯¸í„°
    - **íŠ¸ë¦¬ ê°œìˆ˜**: ìƒì„±í•  ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ì˜ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì•ˆì •ì ì´ë‚˜ ëŠë ¤ì§)
    - **ìµœëŒ€ ê¹Šì´**: ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ (ê¹Šì„ìˆ˜ë¡ ê³¼ì í•© ìœ„í—˜)
    
    #### ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°
    - **íšŒê·€ ìœ í˜•**: 
        - Linear: ê¸°ë³¸ ì„ í˜• íšŒê·€
        - Ridge: L2 ê·œì œ ì ìš©
        - Lasso: L1 ê·œì œ ì ìš©
    - **ì•ŒíŒŒ**: ê·œì œ ê°•ë„ (ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ë‹¨ìˆœí•´ì§)
    
    #### LSTM íŒŒë¼ë¯¸í„°
    - **ì‹œí€€ìŠ¤ ê¸¸ì´**: ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„
    - **LSTM ìœ ë‹› ìˆ˜**: ëª¨ë¸ì˜ ë³µì¡ë„ ê²°ì •
    - **Dropout ë¹„ìœ¨**: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë¹„ìœ¨
    - **í•™ìŠµë¥ **: ëª¨ë¸ í•™ìŠµ ì†ë„ ì¡°ì ˆ
    
    ### ğŸ“ˆ ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
    
    #### ì„±ëŠ¥ ì§€í‘œ
    - **MSE (Mean Squared Error)**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ì œê³±í•œ í‰ê· 
        - ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        - ì‹¤ì œ ì£¼ê°€ ë‹¨ìœ„ì˜ ì œê³±
    - **RÂ² Score**: ëª¨ë¸ì´ ì„¤ëª…í•˜ëŠ” ë¶„ì‚°ì˜ ë¹„ìœ¨
        - 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
        - 0~1 ì‚¬ì´ì˜ ê°’
    
    #### ì‹œê°í™”
    - **íŠ¹ì„± ì¤‘ìš”ë„**: ê° ì…ë ¥ ë³€ìˆ˜ê°€ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥
    - **í•™ìŠµ ê³¡ì„ **: ëª¨ë¸ì˜ í•™ìŠµ ì§„í–‰ ìƒí™©
    - **ì˜ˆì¸¡ ê²°ê³¼**: ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²© ë¹„êµ
    """)

# ì‚¬ì´ë“œë°” íŒŒë¼ë¯¸í„° ì„¤ì •
st.sidebar.header("ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •")

# ì£¼ì‹ ì‹¬ë³¼ ì…ë ¥
ticker = st.sidebar.text_input("ì£¼ì‹ ì‹¬ë³¼ ì…ë ¥", "AAPL")

# ë‚ ì§œ ë²”ìœ„ ì„ íƒ
col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input("ì‹œì‘ì¼", datetime.now() - timedelta(days=365*3))
with col2:
    end_date = st.date_input("ì¢…ë£Œì¼", datetime.now())

# ëª¨ë¸ ì„ íƒ
model_type = st.sidebar.selectbox(
    "ëª¨ë¸ ì„ íƒ",
    ["Random Forest", "ì„ í˜• íšŒê·€", "LSTM", "XGBoost", "LightGBM"]
)

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹ ì˜µì…˜
enable_auto_tuning = st.sidebar.checkbox("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹", value=False)

# Random Forest íŒŒë¼ë¯¸í„°
if model_type == "Random Forest":
    st.sidebar.subheader("Random Forest íŒŒë¼ë¯¸í„°")
    n_estimators = st.sidebar.slider(
        "íŠ¸ë¦¬ ê°œìˆ˜ (n_estimators)", 
        min_value=10, 
        max_value=500, 
        value=100,
        help="ë” ë§ì€ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ ì•ˆì •ì„±ì´ í–¥ìƒë˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ì¦ê°€í•©ë‹ˆë‹¤."
    )
    
    max_depth = st.sidebar.slider(
        "ìµœëŒ€ ê¹Šì´ (max_depth)", 
        min_value=1, 
        max_value=50, 
        value=10,
        help="íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ë¥¼ ì œí•œí•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤."
    )

# ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°
elif model_type == "ì„ í˜• íšŒê·€":
    st.sidebar.subheader("ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°")
    regression_type = st.sidebar.selectbox(
        "íšŒê·€ ëª¨ë¸ ìœ í˜•",
        ["Linear", "Ridge", "Lasso"]
    )
    
    if regression_type in ["Ridge", "Lasso"]:
        alpha = st.sidebar.slider(
            "ì•ŒíŒŒ (ê·œì œ ê°•ë„)", 
            min_value=0.0, 
            max_value=10.0, 
            value=1.0,
            help="ë†’ì€ ê°’ì€ ë” ê°•í•œ ê·œì œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
        )

# LSTM íŒŒë¼ë¯¸í„°
elif model_type == "LSTM":
    st.sidebar.subheader("LSTM íŒŒë¼ë¯¸í„°")
    sequence_length = st.sidebar.slider(
        "ì‹œí€€ìŠ¤ ê¸¸ì´", 
        min_value=5, 
        max_value=60, 
        value=30,
        help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„°ì˜ ê¸°ê°„"
    )
    
    lstm_units = st.sidebar.slider(
        "LSTM ìœ ë‹› ìˆ˜", 
        min_value=32, 
        max_value=256, 
        value=128,
        help="ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."
    )
    
    dropout_rate = st.sidebar.slider(
        "Dropout ë¹„ìœ¨", 
        min_value=0.0, 
        max_value=0.5, 
        value=0.2,
        help="ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ dropout ë¹„ìœ¨"
    )
    
    learning_rate = st.sidebar.slider(
        "í•™ìŠµë¥ ", 
        min_value=0.0001, 
        max_value=0.01, 
        value=0.001,
        format="%.4f",
        help="ëª¨ë¸ì˜ í•™ìŠµ ì†ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤."
    )

# ê³µí†µ íŒŒë¼ë¯¸í„°
test_size = st.sidebar.slider(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 
    min_value=0.1, 
    max_value=0.4, 
    value=0.2,
    help="ì „ì²´ ë°ì´í„° ì¤‘ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ë¹„ìœ¨ì„ ì„¤ì •í•©ë‹ˆë‹¤."
)

# ë°ì´í„° ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
@st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹œ
def get_stock_data(ticker, start, end):
    try:
        data = yf.download(ticker, start=start, end=end)
        if data.empty:
            st.error(f"'{ticker}' ì‹¬ë³¼ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ì£¼ì‹ ì‹¬ë³¼ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return None
        data.reset_index(inplace=True)
        st.success(f"{ticker} ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ({len(data)} ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸)")
        return data
    except Exception as e:
        st.error(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.info("ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\n- ì¸í„°ë„· ì—°ê²° ìƒíƒœ\n- ì£¼ì‹ ì‹¬ë³¼ì˜ ì •í™•ì„±\n- ì„ íƒí•œ ë‚ ì§œ ë²”ìœ„ì˜ ìœ íš¨ì„±")
        return None

def validate_parameters(model_type, **params):
    """ëª¨ë¸ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬"""
    try:
        if model_type == "Random Forest":
            if params.get('n_estimators', 0) < 10:
                st.warning(
                    "íŠ¸ë¦¬ ê°œìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. "
                    "ìµœì†Œ 10ê°œ ì´ìƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                )
            if params.get('max_depth', 0) > 30:
                st.warning(
                    "íŠ¸ë¦¬ ê¹Šì´ê°€ ê¹ŠìŠµë‹ˆë‹¤. "
                    "ê³¼ì í•©ì˜ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤."
                )
        
        elif model_type == "LSTM":
            if params.get('sequence_length', 0) < 10:
                st.warning(
                    "ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. "
                    "ì˜ˆì¸¡ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
            if params.get('dropout_rate', 0) > 0.5:
                st.warning(
                    "Dropout ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. "
                    "í•™ìŠµì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
        
        return True
    except Exception as e:
        st.error(f"íŒŒë¼ë¯¸í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

# LSTM ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜
def prepare_lstm_data(data, sequence_length):
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data[['Close']])
    
    X, y = [], []
    for i in range(len(scaled_data) - sequence_length):
        X.append(scaled_data[i:(i + sequence_length), 0])
        y.append(scaled_data[i + sequence_length, 0])
    
    X = np.array(X)
    y = np.array(y)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    
    return X, y, scaler

def get_model_and_params(model_type):
    """ëª¨ë¸ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ë°˜í™˜"""
    if model_type == "Random Forest":
        model = RandomForestRegressor(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 10, 15],
            'min_samples_split': [2, 5, 10]
        }
    elif model_type == "XGBoost":
        model = XGBRegressor(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    elif model_type == "LightGBM":
        model = LGBMRegressor(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'num_leaves': [31, 62, 127],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    else:
        return None, None
    
    return model, param_grid

def auto_tune_model(model, param_grid, X_train, y_train):
    """GridSearchCVë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
    with st.spinner("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘..."):
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grid,
            cv=5,
            n_jobs=-1,
            scoring='neg_mean_squared_error'
        )
        grid_search.fit(X_train, y_train)
        
        st.success("ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        st.write("ìµœì  íŒŒë¼ë¯¸í„°:", grid_search.best_params_)
        st.write("ìµœì  ì ìˆ˜:", -grid_search.best_score_)
        
        return grid_search.best_estimator_

def plot_feature_importance(model, feature_names):
    """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
    if hasattr(model, 'feature_importances_'):
        importances = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        fig = px.bar(
            importances,
            x='feature',
            y='importance',
            title='íŠ¹ì„± ì¤‘ìš”ë„'
        )
        st.plotly_chart(fig)
    else:
        st.info("ì´ ëª¨ë¸ì€ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def plot_learning_curves(history):
    """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
    if history is not None and hasattr(history, 'history'):
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                y=history.history['loss'],
                name='Train Loss'
            )
        )
        if 'val_loss' in history.history:
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'],
                    name='Validation Loss'
                )
            )
        fig.update_layout(
            title='í•™ìŠµ ê³¡ì„ ',
            xaxis_title='Epoch',
            yaxis_title='Loss'
        )
        st.plotly_chart(fig)

def evaluate_model(model, X_test, y_test, scaler=None):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    start_time = time.time()
    y_pred = model.predict(X_test)
    inference_time = time.time() - start_time
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = {
        'MAE': mean_absolute_error(y_test, y_pred),
        'MSE': mean_squared_error(y_test, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
        'R2 Score': r2_score(y_test, y_pred),
        'ì¶”ë¡  ì‹œê°„': f"{inference_time:.4f}ì´ˆ"
    }
    
    # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    metrics_df = pd.DataFrame([metrics]).T
    metrics_df.columns = ['ê°’']
    st.table(metrics_df)
    
    # ì˜ˆì¸¡ vs ì‹¤ì œ ê·¸ë˜í”„
    fig = go.Figure()
    fig.add_trace(
        go.Scatter(
            x=y_test,
            y=y_pred,
            mode='markers',
            name='ì˜ˆì¸¡ vs ì‹¤ì œ',
            marker=dict(color='blue', opacity=0.5)
        ))
    fig.add_trace(
        go.Scatter(
            x=[y_test.min(), y_test.max()],
            y=[y_test.min(), y_test.max()],
            mode='lines',
            name='ì´ìƒì ì¸ ì˜ˆì¸¡',
            line=dict(color='red', dash='dash')
        ))
    fig.update_layout(
        title='ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ë¹„êµ',
        xaxis_title='ì‹¤ì œ ê°’',
        yaxis_title='ì˜ˆì¸¡ ê°’'
    )
    st.plotly_chart(fig)
    
    return metrics

# ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€
def calculate_technical_indicators(data):
    """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
    # RSI
    delta = data['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    data['RSI'] = 100 - (100 / (1 + rs))
    
    # MACD
    exp1 = data['Close'].ewm(span=12, adjust=False).mean()
    exp2 = data['Close'].ewm(span=26, adjust=False).mean()
    data['MACD'] = exp1 - exp2
    data['Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()
    
    # Bollinger Bands
    data['MA20'] = data['Close'].rolling(window=20).mean()
    data['BB_upper'] = data['MA20'] + 2 * data['Close'].rolling(window=20).std()
    data['BB_lower'] = data['MA20'] - 2 * data['Close'].rolling(window=20).std()
    
    return data

# í™•ë¥ ì  ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤ ì¶”ê°€
class ProbabilisticPredictor:
    def __init__(self, data, sequence_length=30):
        self.data = data
        self.sequence_length = sequence_length
        self.models = []
        self.prepare_data()
        
    def prepare_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # íŠ¹ì„± ìƒì„±
        self.data['Returns'] = self.data['Close'].pct_change()
        self.data['Volatility'] = self.data['Returns'].rolling(window=20).std()
        self.data['MA20'] = self.data['Close'].rolling(window=20).mean()
        
        # NaN ì œê±°
        self.data.dropna(inplace=True)
        
        # ì…ë ¥ íŠ¹ì„± ì„ íƒ
        self.features = ['Open', 'High', 'Low', 'Volume', 'Returns', 'Volatility', 'MA20']
        self.X = self.data[self.features]
        self.y = self.data['Close']
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        self.scaler = MinMaxScaler()
        self.X_scaled = self.scaler.fit_transform(self.X)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_size = int(len(self.X_scaled) * 0.8)
        self.X_train = self.X_scaled[:train_size]
        self.X_test = self.X_scaled[train_size:]
        self.y_train = self.y[:train_size]
        self.y_test = self.y[train_size:]
    
    def train_ensemble(self):
        """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ"""
        self.models = []
        base_models = [
            RandomForestRegressor(n_estimators=100, random_state=42),
            XGBRegressor(random_state=42)
        ]
        
        if LIGHTGBM_AVAILABLE:
            base_models.append(LGBMRegressor(random_state=42))
        
        for model in base_models:
            model.fit(self.X_train, self.y_train)
            self.models.append(model)
        
        return self.models
    
    def predict_probability(self, X=None):
        """í™•ë¥ ì  ì˜ˆì¸¡ ìˆ˜í–‰"""
        if X is None:
            X = self.X_test
            
        if len(self.models) == 0:
            self.train_ensemble()
        
        predictions = []
        for model in self.models:
            pred = model.predict(X)
            predictions.append(pred)
        
        predictions = np.array(predictions)
        mean_pred = np.mean(predictions, axis=0)
        std_pred = np.std(predictions, axis=0)
        
        return mean_pred, std_pred

# íˆ¬ì ì‹ í˜¸ ìƒì„± í•¨ìˆ˜ ì¶”ê°€
def generate_trading_signals(data, pred_mean, pred_std):
    """ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ì‹ í˜¸ ìƒì„±"""
    try:
        signals = pd.DataFrame(index=data.index[-len(pred_mean):])
        
        # ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ì‹ í˜¸
        signals['RSI_signal'] = np.where(data['RSI'].iloc[-len(pred_mean):] < 30, 'BUY',
                                       np.where(data['RSI'].iloc[-len(pred_mean):] > 70, 'SELL', 'HOLD'))
        
        signals['MACD_signal'] = np.where(data['MACD'].iloc[-len(pred_mean):] > data['Signal'].iloc[-len(pred_mean):], 'BUY',
                                        np.where(data['MACD'].iloc[-len(pred_mean):] < data['Signal'].iloc[-len(pred_mean):], 'SELL', 'HOLD'))
        
        # ë³¼ë¦°ì € ë°´ë“œ ê¸°ë°˜ ì‹ í˜¸
        signals['BB_signal'] = np.where(data['Close'].iloc[-len(pred_mean):] < data['BB_lower'].iloc[-len(pred_mean):], 'BUY',
                                      np.where(data['Close'].iloc[-len(pred_mean):] > data['BB_upper'].iloc[-len(pred_mean):], 'SELL', 'HOLD'))
        
        # í™•ë¥ ì  ì˜ˆì¸¡ ê¸°ë°˜ ì‹ í˜¸
        current_price = data['Close'].iloc[-len(pred_mean):]
        confidence_interval = 1.96 * pred_std
        
        signals['Pred_signal'] = np.where(pred_mean - confidence_interval > current_price, 'BUY',
                                        np.where(pred_mean + confidence_interval < current_price, 'SELL', 'HOLD'))
        
        # ì¢…í•© ì‹ í˜¸ (ìµœë¹ˆê°’ ê¸°ì¤€)
        signals['Final_signal'] = signals.mode(axis=1)[0]
        
        return signals['Final_signal']
        
    except Exception as e:
        st.error(f"ë§¤ë§¤ ì‹ í˜¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€
def calculate_risk_metrics(data, signals):
    """ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì§€í‘œ ê³„ì‚°"""
    risk_metrics = {}
    
    # ë³€ë™ì„± (20ì¼)
    volatility = data['Close'].pct_change().rolling(20).std() * np.sqrt(252)
    risk_metrics['Volatility'] = volatility.iloc[-1]  # ìˆ˜ì •ëœ ë¶€ë¶„
    
    # ìƒ¤í”„ ë¹„ìœ¨
    returns = data['Close'].pct_change()
    risk_free_rate = 0.02  # ì—°ê°„ ê¸°ì¤€
    excess_returns = returns - risk_free_rate/252
    risk_metrics['Sharpe_ratio'] = (np.sqrt(252) * excess_returns.mean() / returns.std())
    
    # ìµœëŒ€ ë‚™í­
    rolling_max = data['Close'].rolling(252, min_periods=1).max()
    drawdown = (data['Close'] - rolling_max) / rolling_max
    risk_metrics['Max_drawdown'] = drawdown.min()
    
    return risk_metrics

class TechnicalAnalyzer:
    def __init__(self, data):
        self.data = data
        self.features = []
        self.calculate_indicators()
        
    def calculate_indicators(self):
        """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        df = self.data.copy()
        
        # ê¸°ë³¸ ì´ë™í‰ê· 
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['SMA_5'] = df['Close'].rolling(window=5).mean()
        df['SMA_20'] = df['Close'].rolling(window=20).mean()
        df['SMA_60'] = df['Close'].rolling(window=60).mean()
        
        # RSI
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['Close'].ewm(span=12, adjust=False).mean()
        exp2 = df['Close'].ewm(span=26, adjust=False).mean()
        df['MACD'] = exp1 - exp2
        df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        
        # ë³¼ë¦°ì € ë°´ë“œ
        df['BB_middle'] = df['Close'].rolling(window=20).mean()
        bb_std = df['Close'].rolling(window=20).std()
        df['BB_upper'] = df['BB_middle'] + (bb_std * 2)
        df['BB_lower'] = df['BB_middle'] - (bb_std * 2)
        df['BB_Width'] = (df['BB_upper'] - df['BB_lower']) / df['BB_middle']
        
        # ëª¨ë©˜í…€ ì§€í‘œ
        df['ROC'] = df['Close'].pct_change(periods=12) * 100
        df['MOM'] = df['Close'].diff(periods=10)
        
        # ë³€ë™ì„± ì§€í‘œ
        df['ATR'] = self.calculate_atr(df)
        
        # ê±°ë˜ëŸ‰ ì§€í‘œ
        df['OBV'] = self.calculate_obv(df)
        df['Volume_MA'] = df['Volume'].rolling(window=20).mean()
        
        # ì¶”ê°€ íŒŒìƒ ì§€í‘œ
        df['Price_Change'] = df['Close'].pct_change()
        df['Volatility'] = df['Price_Change'].rolling(window=20).std()
        
        # NaN ê°’ ì²˜ë¦¬
        df.fillna(method='bfill', inplace=True)
        df.fillna(method='ffill', inplace=True)
        
        self.data = df
        self.features = [
            'SMA_5', 'SMA_20', 'SMA_60', 'RSI', 'MACD', 'Signal',
            'BB_Width', 'ROC', 'MOM', 'ATR', 'OBV', 'Volume_MA',
            'Price_Change', 'Volatility', 'BB_upper', 'BB_lower'
        ]
        
    def calculate_atr(self, df):
        """ATR(Average True Range) ê³„ì‚°"""
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        return true_range.rolling(14).mean()
    
    def calculate_obv(self, df):
        """OBV(On Balance Volume) ê³„ì‚°"""
        obv = np.zeros(len(df))
        for i in range(1, len(df)):
            if df['Close'].iloc[i] > df['Close'].iloc[i-1]:
                obv[i] = obv[i-1] + df['Volume'].iloc[i]
            elif df['Close'].iloc[i] < df['Close'].iloc[i-1]:
                obv[i] = obv[i-1] - df['Volume'].iloc[i]
            else:
                obv[i] = obv[i-1]
        return obv
    
    def get_features(self):
        """ë¶„ì„ì— ì‚¬ìš©í•  íŠ¹ì„± ë°˜í™˜"""
        return self.data[self.features]

class ProbabilisticAnalyzer:
    def __init__(self, data, test_size=0.2, sequence_length=10):
        self.data = data
        self.test_size = test_size
        self.sequence_length = sequence_length
        self.models = {}
        self.predictions = {}
        self.signal_probabilities = {}
        self.linear_model = None
        self.poly_features = None
        
    def prepare_features(self):
        """ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì„± ì¤€ë¹„"""
        try:
            # ê¸°ë³¸ íŠ¹ì„± ì„ íƒ
            features = [
                'RSI', 'MACD', 'Signal', 'BB_upper', 'BB_lower', 'MA20',
                'Volume', 'Close', 'High', 'Low', 'Open'
            ]
            
            # ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„±
            df = self.data.copy()
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            df['Target'] = df['Close'].shift(-1) > df['Close']
            df['BB_Position'] = (df['Close'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])
            df['Price_Change'] = df['Close'].pct_change()
            df['Volume_Change'] = df['Volume'].pct_change()
            df['ROC'] = df['Close'].pct_change(periods=12) * 100
            df['MOM'] = df['Close'].diff(periods=10)
            df['Volatility'] = df['Close'].pct_change().rolling(window=20).std()
            df['SMA_5'] = df['Close'].rolling(window=5).mean()
            df['SMA_20'] = df['Close'].rolling(window=20).mean()
            df['MA_Cross'] = np.where(df['SMA_5'] > df['SMA_20'], 1, -1)
            
            # ì¶”ê°€ íŠ¹ì„± ëª©ë¡ì— ì¶”ê°€
            features.extend(['BB_Position', 'Price_Change', 'Volume_Change', 
                           'ROC', 'MOM', 'Volatility', 'MA_Cross'])
            
            # NaN ì œê±°
            df = df.dropna()
            
            # ë§ˆì§€ë§‰ í–‰ ì œê±° (ë‹¤ìŒ ë‚  ì¢…ê°€ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ)
            df = df.iloc[:-1]
            
            # ë°ì´í„° ë¶„í• 
            train_size = int(len(df) * (1 - self.test_size))
            
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
            train_data = df[:train_size]
            test_data = df[train_size:]
            
            # X, y ë°ì´í„° ì¤€ë¹„
            self.X_train = train_data[features]
            self.X_test = test_data[features]
            self.y_train = train_data['Target']
            self.y_test = test_data['Target']
            
            # ìŠ¤ì¼€ì¼ë§
            self.scaler = MinMaxScaler()
            self.X_train_scaled = self.scaler.fit_transform(self.X_train)
            self.X_test_scaled = self.scaler.transform(self.X_test)
            
            # LSTMìš© ì‹œí€€ìŠ¤ ë°ì´í„°
            self.X_train_seq = self.create_sequences(self.X_train_scaled)
            self.X_test_seq = self.create_sequences(self.X_test_scaled)
            self.y_train_seq = self.y_train[self.sequence_length:].values
            self.y_test_seq = self.y_test[self.sequence_length:].values
            
            # ì„ í˜• íšŒê·€ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
            self.poly_features = PolynomialFeatures(degree=2, include_bias=False)
            X_train_poly = self.poly_features.fit_transform(self.X_train_scaled)
            X_test_poly = self.poly_features.transform(self.X_test_scaled)
            
            # ì„ í˜• íšŒê·€ìš© íƒ€ê²Ÿ (ë‹¤ìŒ ë‚ ì˜ ì¢…ê°€ ë³€í™”ìœ¨)
            train_returns = train_data['Close'].pct_change().shift(-1).iloc[:-1]
            test_returns = test_data['Close'].pct_change().shift(-1).iloc[:-1]
            
            # íšŒê·€ ë°ì´í„° ì¤€ë¹„
            self.X_train_reg = X_train_poly[:-1]  # ë§ˆì§€ë§‰ í–‰ ì œì™¸
            self.X_test_reg = X_test_poly[:-1]    # ë§ˆì§€ë§‰ í–‰ ì œì™¸
            self.y_train_reg = train_returns.dropna()
            self.y_test_reg = test_returns.dropna()
            
            # ë°ì´í„° ê¸¸ì´ í™•ì¸ ë° ì¡°ì •
            min_train_len = min(len(self.X_train_reg), len(self.y_train_reg))
            min_test_len = min(len(self.X_test_reg), len(self.y_test_reg))
            
            self.X_train_reg = self.X_train_reg[:min_train_len]
            self.y_train_reg = self.y_train_reg[:min_train_len]
            self.X_test_reg = self.X_test_reg[:min_test_len]
            self.y_test_reg = self.y_test_reg[:min_test_len]
            
            # ë°ì´í„° ì¤€ë¹„ ìƒíƒœ í™•ì¸
            assert len(self.X_train_reg) == len(self.y_train_reg), "í•™ìŠµ ë°ì´í„° ê¸¸ì´ ë¶ˆì¼ì¹˜"
            assert len(self.X_test_reg) == len(self.y_test_reg), "í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸¸ì´ ë¶ˆì¼ì¹˜"
            
            st.success("íŠ¹ì„± ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return features
            
        except Exception as e:
            st.error(f"íŠ¹ì„± ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.write("ë°ì´í„° í˜•íƒœ:", self.data.shape)
            return None
    
    def create_sequences(self, data):
        """LSTMì„ ìœ„í•œ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
        sequences = []
        for i in range(len(data) - self.sequence_length):
            sequences.append(data[i:(i + self.sequence_length)])
        return np.array(sequences)
    
    def calculate_model_probabilities(self):
        """ê° ëª¨ë¸ë³„ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ í™•ë¥  ê³„ì‚°"""
        try:
            for name, model in self.models.items():
                if name == 'LSTM':
                    pred_proba = model.predict(self.X_test_seq, verbose=0)
                elif name == 'Linear Regression':
                    # ì„ í˜• íšŒê·€ì˜ ê²½ìš° ì˜ˆì¸¡ê°’ì„ í™•ë¥ ë¡œ ë³€í™˜
                    pred = model.predict(self.X_test_reg)
                    
                    # Min-Max ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ 0~1 ë²”ìœ„ë¡œ ë³€í™˜
                    pred_scaled = (pred - pred.min()) / (pred.max() - pred.min())
                    pred_proba = pred_scaled
                else:
                    pred_proba = model.predict_proba(self.X_test_scaled)[:, 1]
                
                # dtypeì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ê²½ê³  ë©”ì‹œì§€ ì œê±°
                signals = pd.Series(
                    index=self.X_test.index[-len(pred_proba):],
                    dtype='object'
                )
                
                if name == 'Linear Regression':
                    # ì„ í˜• íšŒê·€ì˜ ê²½ìš° ë³€í™”ìœ¨ ê¸°ë°˜ìœ¼ë¡œ ì‹ í˜¸ ìƒì„±
                    signals.loc[pred > 0.01] = 'BUY'     # 1% ì´ìƒ ìƒìŠ¹ ì˜ˆì¸¡
                    signals.loc[pred < -0.01] = 'SELL'   # 1% ì´ìƒ í•˜ë½ ì˜ˆì¸¡
                    signals.loc[(pred >= -0.01) & (pred <= 0.01)] = 'HOLD'
                else:
                    # ë‹¤ë¥¸ ëª¨ë¸ë“¤ì˜ ê²½ìš° í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ì‹ í˜¸ ìƒì„±
                    signals.loc[pred_proba > 0.66] = 'BUY'
                    signals.loc[pred_proba < 0.33] = 'SELL'
                    signals.loc[(pred_proba >= 0.33) & (pred_proba <= 0.66)] = 'HOLD'
                
                self.predictions[name] = signals
                
                # ì‹ í˜¸ë³„ í™•ë¥  ê³„ì‚°
                total_signals = len(signals)
                signal_counts = signals.value_counts()
                
                self.signal_probabilities[name] = {
                    'BUY': signal_counts.get('BUY', 0) / total_signals * 100,
                    'SELL': signal_counts.get('SELL', 0) / total_signals * 100,
                    'HOLD': signal_counts.get('HOLD', 0) / total_signals * 100
                }
                
        except Exception as e:
            st.error(f"í™•ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
        
        return True

    def train_all_models(self):
        """ëª¨ë“  ëª¨ë¸ í•™ìŠµ"""
        try:
            features = self.prepare_features()
            if features is None:
                return False
            
            # ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ
            try:
                linear_model = LinearRegression()
                linear_model.fit(self.X_train_reg, self.y_train_reg)
                self.models['Linear Regression'] = linear_model
                
                # ì„ í˜• íšŒê·€ ì˜ˆì¸¡ì„ ì‹ í˜¸ë¡œ ë³€í™˜
                y_pred_reg = linear_model.predict(self.X_test_reg)
                signals = pd.Series(index=self.y_test_reg.index, dtype='object')
                
                # ë³€í™”ìœ¨ì— ë”°ë¥¸ ì‹ í˜¸ ìƒì„±
                signals.loc[y_pred_reg > 0.01] = 'BUY'    # 1% ì´ìƒ ìƒìŠ¹ ì˜ˆì¸¡
                signals.loc[y_pred_reg < -0.01] = 'SELL'  # 1% ì´ìƒ í•˜ë½ ì˜ˆì¸¡
                signals.loc[(y_pred_reg >= -0.01) & (y_pred_reg <= 0.01)] = 'HOLD'
                
                self.predictions['Linear Regression'] = signals
                
            except Exception as e:
                st.warning(f"ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                
            # Random Forest
            rf_model = RandomForestClassifier(
                n_estimators=100, 
                random_state=42,
                class_weight='balanced'
            )
            rf_model.fit(self.X_train_scaled, self.y_train)
            self.models['Random Forest'] = rf_model
            
            # XGBoost
            if XGBOOST_AVAILABLE:
                xgb_model = XGBClassifier(
                    n_estimators=100,
                    max_depth=3,
                    learning_rate=0.1,
                    random_state=42,
                    scale_pos_weight=1
                )
                xgb_model.fit(self.X_train_scaled, self.y_train)
                self.models['XGBoost'] = xgb_model
            
            # LightGBM - íŒŒë¼ë¯¸í„° ìˆ˜ì •
            if LIGHTGBM_AVAILABLE:
                # ê²½ê³  ë©”ì‹œì§€ ì„ì‹œ ë¹„í™œì„±í™”
                import warnings
                warnings.filterwarnings('ignore', category=UserWarning)
                warnings.filterwarnings('ignore', category=FutureWarning)
                
                lgb_model = LGBMClassifier(
                    n_estimators=1000,  # ì¦ê°€ëœ íŠ¸ë¦¬ ìˆ˜
                    num_leaves=15,      # ê°ì†Œëœ ì ë…¸ë“œ ìˆ˜
                    max_depth=4,        # ê°ì†Œëœ íŠ¸ë¦¬ ê¹Šì´
                    learning_rate=0.05, # ê°ì†Œëœ í•™ìŠµë¥ 
                    min_child_samples=5,  # ê°ì†Œëœ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
                    min_child_weight=1,  # ì¦ê°€ëœ ìµœì†Œ ê°€ì¤‘ì¹˜
                    min_split_gain=0.1,  # ì¦ê°€ëœ ë¶„í•  ì„ê³„ê°’
                    subsample=0.8,
                    colsample_bytree=0.8,
                    random_state=42,
                    class_weight='balanced',
                    force_col_wise=True  # ì»¬ëŸ¼ ë°©ì‹ ë©€í‹°ìŠ¤ë ˆë”© ê°•ì œ
                )
                
                # ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬
                X_train_lgb, X_val_lgb, y_train_lgb, y_val_lgb = train_test_split(
                    self.X_train_scaled,
                    self.y_train,
                    test_size=0.2,
                    random_state=42,
                    stratify=self.y_train  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
                )
                
                # ëª¨ë¸ í•™ìŠµ
                try:
                    lgb_model.fit(
                        X_train_lgb,
                        y_train_lgb,
                        eval_set=[(X_val_lgb, y_val_lgb)],
                        eval_metric='auc',  # ë³€ê²½ëœ í‰ê°€ ë©”íŠ¸ë¦­
                        callbacks=[
                            lgb.early_stopping(stopping_rounds=50),  # ì¦ê°€ëœ ì¡°ê¸° ì¢…ë£Œ ë¼ìš´ë“œ
                            lgb.log_evaluation(period=0)
                        ]
                    )
                    
                    self.models['LightGBM'] = lgb_model
                    
                except Exception as e:
                    st.warning(f"LightGBM í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.info("ë‹¤ë¥¸ ëª¨ë¸ë“¤ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                
                # ê²½ê³  ë©”ì‹œì§€ ë‹¤ì‹œ í™œì„±í™”
                warnings.resetwarnings()
            
            # LSTM ëª¨ë¸ ìˆ˜ì •
            try:
                input_shape = (self.sequence_length, len(features))
                inputs = Input(shape=input_shape)
                
                # LSTM ë ˆì´ì–´ êµ¬ì„± ìˆ˜ì •
                x = LSTM(64, return_sequences=True, 
                        kernel_initializer='glorot_uniform',
                        recurrent_initializer='orthogonal')(inputs)
                x = BatchNormalization()(x)
                x = Dropout(0.3)(x)
                
                x = LSTM(32, 
                        kernel_initializer='glorot_uniform',
                        recurrent_initializer='orthogonal')(x)
                x = BatchNormalization()(x)
                x = Dropout(0.3)(x)
                
                x = Dense(16, activation='relu')(x)
                x = BatchNormalization()(x)
                outputs = Dense(1, activation='sigmoid')(x)
                
                lstm_model = Model(inputs=inputs, outputs=outputs)
                
                # ì»´íŒŒì¼ ì„¤ì • ìˆ˜ì •
                optimizer = Adam(
                    learning_rate=0.001,
                    clipnorm=1.0  # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ ì¶”ê°€
                )
                
                lstm_model.compile(
                    optimizer=optimizer,
                    loss='binary_crossentropy',
                    metrics=['accuracy']
                )
                
                # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
                class_weights = compute_class_weight(
                    'balanced',
                    classes=np.unique(self.y_train_seq),
                    y=self.y_train_seq
                )
                class_weight_dict = dict(enumerate(class_weights))
                
                # Early Stopping ì½œë°± ì¶”ê°€
                early_stopping = EarlyStopping(
                    monitor='loss',
                    patience=5,
                    restore_best_weights=True
                )
                
                # ëª¨ë¸ í•™ìŠµ
                lstm_model.fit(
                    self.X_train_seq, 
                    self.y_train_seq,
                    epochs=50, 
                    batch_size=32,
                    class_weight=class_weight_dict,
                    callbacks=[early_stopping],
                    validation_split=0.2,
                    verbose=0
                )
                
                self.models['LSTM'] = lstm_model
                
            except Exception as e:
                st.warning(f"LSTM í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.info("ë‹¤ë¥¸ ëª¨ë¸ë“¤ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            
            return self.calculate_model_probabilities()
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def compare_models(self):
        """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„"""
        try:
            # ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ ì €ì¥
            performance_metrics = {}
            
            for name, model in self.models.items():
                metrics = {}
                
                if name == 'Linear Regression':
                    # ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œ
                    y_pred = model.predict(self.X_test_reg)
                    metrics['R2'] = r2_score(self.y_test_reg, y_pred)
                    metrics['MAE'] = mean_absolute_error(self.y_test_reg, y_pred)
                    metrics['RMSE'] = np.sqrt(mean_squared_error(self.y_test_reg, y_pred))
                    
                    # ë°©í–¥ì„± ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°
                    direction_accuracy = np.mean(
                        (y_pred > 0) == (self.y_test_reg > 0)
                    ) * 100
                    metrics['ë°©í–¥ì„± ì •í™•ë„'] = direction_accuracy
                    
                elif name == 'LSTM':
                    # LSTM ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œ
                    y_pred = (model.predict(self.X_test_seq) > 0.5).astype(int)
                    metrics['ì •í™•ë„'] = accuracy_score(self.y_test_seq, y_pred)
                    metrics['ì •ë°€ë„'] = precision_score(self.y_test_seq, y_pred)
                    metrics['ì¬í˜„ìœ¨'] = recall_score(self.y_test_seq, y_pred)
                    metrics['F1 ì ìˆ˜'] = f1_score(self.y_test_seq, y_pred)
                    
                else:
                    # ë¶„ë¥˜ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ ì§€í‘œ
                    y_pred = model.predict(self.X_test_scaled)
                    metrics['ì •í™•ë„'] = accuracy_score(self.y_test, y_pred)
                    metrics['ì •ë°€ë„'] = precision_score(self.y_test, y_pred)
                    metrics['ì¬í˜„ìœ¨'] = recall_score(self.y_test, y_pred)
                    metrics['F1 ì ìˆ˜'] = f1_score(self.y_test, y_pred)
                
                performance_metrics[name] = metrics
            
            # ì„±ëŠ¥ ì§€í‘œ ì‹œê°í™”
            st.write("### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ")
            
            # 1. ì„±ëŠ¥ ì§€í‘œ í…Œì´ë¸”
            metrics_df = pd.DataFrame(performance_metrics).round(4)
            st.dataframe(
                metrics_df.style.background_gradient(cmap='YlOrRd')
            )
            
            # 2. ëª¨ë¸ë³„ ì£¼ìš” ì§€í‘œ ì‹œê°í™”
            fig = go.Figure()
            
            for name, metrics in performance_metrics.items():
                if name == 'Linear Regression':
                    # ì„ í˜• íšŒê·€ ëª¨ë¸ì€ ë°©í–¥ì„± ì •í™•ë„ë§Œ í‘œì‹œ
                    fig.add_trace(
                        go.Bar(
                            name=name,
                            x=['ë°©í–¥ì„± ì •í™•ë„'],
                            y=[metrics['ë°©í–¥ì„± ì •í™•ë„']],
                            text=[f"{metrics['ë°©í–¥ì„± ì •í™•ë„']:.2f}%"],
                            textposition='auto'
                        )
                    )
                else:
                    # ë‹¤ë¥¸ ëª¨ë¸ë“¤ì€ ì •í™•ë„ì™€ F1 ì ìˆ˜ í‘œì‹œ
                    fig.add_trace(
                        go.Bar(
                            name=name,
                            x=['ì •í™•ë„', 'F1 ì ìˆ˜'],
                            y=[metrics['ì •í™•ë„'], metrics['F1 ì ìˆ˜']],
                            text=[f"{metrics['ì •í™•ë„']:.2f}", f"{metrics['F1 ì ìˆ˜']:.2f}"],
                            textposition='auto'
                        )
                    )
            
            fig.update_layout(
                title='ëª¨ë¸ë³„ ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ',
                xaxis_title='ì§€í‘œ',
                yaxis_title='ì ìˆ˜',
                barmode='group',
                height=500
            )
            
            st.plotly_chart(fig)
            
            # 3. ëª¨ë¸ ìˆœìœ„ ê³„ì‚°
            model_ranks = {}
            for name, metrics in performance_metrics.items():
                if name == 'Linear Regression':
                    model_ranks[name] = metrics['ë°©í–¥ì„± ì •í™•ë„']
                else:
                    # ì •í™•ë„ì™€ F1 ì ìˆ˜ì˜ í‰ê· ìœ¼ë¡œ ìˆœìœ„ ê³„ì‚°
                    model_ranks[name] = (metrics['ì •í™•ë„'] + metrics['F1 ì ìˆ˜']) / 2
            
            ranks_df = pd.DataFrame(
                model_ranks.items(), 
                columns=['ëª¨ë¸', 'ì¢…í•© ì ìˆ˜']
            ).sort_values('ì¢…í•© ì ìˆ˜', ascending=False)
            
            st.write("### ëª¨ë¸ ìˆœìœ„")
            st.dataframe(
                ranks_df.style.background_gradient(
                    cmap='YlOrRd',
                    subset=['ì¢…í•© ì ìˆ˜']
                )
            )
            
            return performance_metrics
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def plot_feature_importance(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
        try:
            st.write("### ëª¨ë¸ë³„ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
            
            for name, model in self.models.items():
                if name == 'Linear Regression':
                    # ì„ í˜• íšŒê·€ ê³„ìˆ˜ì˜ ì ˆëŒ€ê°’ì„ ì¤‘ìš”ë„ë¡œ ì‚¬ìš©
                    feature_names = self.poly_features.get_feature_names_out(self.X_train.columns)
                    importance = np.abs(model.coef_)
                    
                elif name == 'LSTM':
                    # LSTMì€ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° ìƒëµ
                    continue
                    
                elif name in ['Random Forest', 'XGBoost', 'LightGBM']:
                    # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„
                    feature_names = self.X_train.columns
                    if hasattr(model, 'feature_importances_'):
                        importance = model.feature_importances_
                    else:
                        continue
                else:
                    continue
                
                # íŠ¹ì„± ì¤‘ìš”ë„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                importance_df = pd.DataFrame({
                    'Feature': feature_names,
                    'Importance': importance
                })
                
                # ì¤‘ìš”ë„ ê¸°ì¤€ ì •ë ¬
                importance_df = importance_df.sort_values(
                    'Importance', 
                    ascending=False
                ).reset_index(drop=True)
                
                # ìƒìœ„ 15ê°œ íŠ¹ì„±ë§Œ ì„ íƒ
                importance_df = importance_df.head(15)
                
                # íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
                fig = go.Figure()
                
                fig.add_trace(
                    go.Bar(
                        x=importance_df['Importance'],
                        y=importance_df['Feature'],
                        orientation='h',
                        marker=dict(
                            color=importance_df['Importance'],
                            colorscale='YlOrRd'
                        )
                    )
                )
                
                fig.update_layout(
                    title=f'{name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„',
                    xaxis_title='ì¤‘ìš”ë„',
                    yaxis_title='íŠ¹ì„±',
                    height=600,
                    yaxis=dict(autorange="reversed")
                )
                
                st.plotly_chart(fig)
                
                # íŠ¹ì„± ì¤‘ìš”ë„ í…Œì´ë¸”
                st.write(f"#### {name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ ìƒì„¸")
                st.dataframe(
                    importance_df.style.background_gradient(
                        cmap='YlOrRd',
                        subset=['Importance']
                    )
                )
                
                # íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
                if name == 'Linear Regression':
                    st.write("#### ì£¼ìš” íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„")
                    top_features = importance_df['Feature'].head(10).tolist()
                    
                    # ë‹¤í•­ì‹ íŠ¹ì„±ì˜ ê²½ìš° ì›ë³¸ íŠ¹ì„±ë§Œ ì„ íƒ
                    original_features = [f for f in self.X_train.columns if f in top_features]
                    
                    if original_features:
                        corr_matrix = self.X_train[original_features].corr()
                        
                        fig = go.Figure(data=go.Heatmap(
                            z=corr_matrix.values,
                            x=corr_matrix.columns,
                            y=corr_matrix.columns,
                            colorscale='RdBu',
                            zmin=-1,
                            zmax=1
                        ))
                        
                        fig.update_layout(
                            title='ì£¼ìš” íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„',
                            height=600,
                            width=800
                        )
                        
                        st.plotly_chart(fig)
            
        except Exception as e:
            st.error(f"íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def plot_roc_curves(self):
        """ëª¨ë¸ë³„ ROC ê³¡ì„  ì‹œê°í™”"""
        try:
            st.write("### ëª¨ë¸ë³„ ROC ê³¡ì„  ë¹„êµ")
            
            fig = go.Figure()
            auc_scores = {}
            
            # Random classifier ê¸°ì¤€ì„ 
            fig.add_trace(
                go.Scatter(
                    x=[0, 1],
                    y=[0, 1],
                    line=dict(dash='dash', color='gray'),
                    name='Random Classifier'
                )
            )
            
            for name, model in self.models.items():
                try:
                    if name == 'Linear Regression':
                        # ì„ í˜• íšŒê·€ì˜ ê²½ìš° ì˜ˆì¸¡ê°’ì„ ì´ì§„ ë¶„ë¥˜ë¡œ ë³€í™˜
                        y_pred = model.predict(self.X_test_reg)
                        y_true = (self.y_test_reg > 0).astype(int)
                        y_score = (y_pred - y_pred.min()) / (y_pred.max() - y_pred.min())
                        
                    elif name == 'LSTM':
                        # LSTMì˜ ê²½ìš° ì˜ˆì¸¡ í™•ë¥  ì§ì ‘ ì‚¬ìš©
                        y_true = self.y_test_seq
                        y_score = model.predict(self.X_test_seq).ravel()
                        
                    else:
                        # ë‹¤ë¥¸ ë¶„ë¥˜ ëª¨ë¸ë“¤
                        y_true = self.y_test
                        y_score = model.predict_proba(self.X_test_scaled)[:, 1]
                    
                    # ROC ê³¡ì„  ê³„ì‚°
                    fpr, tpr, _ = roc_curve(y_true, y_score)
                    auc_score = auc(fpr, tpr)
                    auc_scores[name] = auc_score
                    
                    # ROC ê³¡ì„  ì¶”ê°€
                    fig.add_trace(
                        go.Scatter(
                            x=fpr,
                            y=tpr,
                            name=f'{name} (AUC = {auc_score:.3f})',
                            mode='lines'
                        )
                    )
                    
                except Exception as model_error:
                    st.warning(f"{name} ëª¨ë¸ì˜ ROC ê³¡ì„ ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(model_error)}")
                    continue
            
            # ê·¸ë˜í”„ ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig.update_layout(
                title='ROC Curves Comparison',
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                height=600,
                width=800,
                showlegend=True,
                legend=dict(
                    yanchor="bottom",
                    y=0.01,
                    xanchor="right",
                    x=0.99
                )
            )
            
            # ê·¸ë¦¬ë“œ ì¶”ê°€
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
            
            st.plotly_chart(fig)
            
            # AUC ì ìˆ˜ í…Œì´ë¸”
            if auc_scores:
                st.write("### AUC ì ìˆ˜ ë¹„êµ")
                auc_df = pd.DataFrame(
                    auc_scores.items(),
                    columns=['ëª¨ë¸', 'AUC ì ìˆ˜']
                ).sort_values('AUC ì ìˆ˜', ascending=False)
                
                st.dataframe(
                    auc_df.style.background_gradient(
                        cmap='YlOrRd',
                        subset=['AUC ì ìˆ˜']
                    ).format({'AUC ì ìˆ˜': '{:.4f}'})
                )
            
        except Exception as e:
            st.error(f"ROC ê³¡ì„  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("ì¼ë¶€ ëª¨ë¸ì—ì„œ ROC ê³¡ì„ ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

class ModelSignalAnalyzer:
    def __init__(self, models, data, predictions):
        self.models = models
        self.data = data
        self.predictions = predictions
        self.performance_metrics = {}
        self.returns = self.data['Close'].pct_change().fillna(0)  # NaN ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬
        
    def analyze_signals(self):
        """ëª¨ë¸ë³„ ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„"""
        try:
            signal_metrics = {}
            
            for name, signals in self.predictions.items():
                # ë§¤ë§¤ í¬ì§€ì…˜ ì´ˆê¸°í™”
                positions = pd.Series(0, index=signals.index)
                positions[signals == 'BUY'] = 1
                positions[signals == 'SELL'] = -1
                
                # í•´ë‹¹ ê¸°ê°„ì˜ ìˆ˜ìµë¥  ê³„ì‚°
                period_returns = self.returns[signals.index]
                strategy_returns = positions * period_returns
                
                # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
                cumulative_returns = (1 + strategy_returns).cumprod()
                
                # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
                total_return = cumulative_returns.iloc[-1] - 1
                sharpe_ratio = np.sqrt(252) * strategy_returns.mean() / strategy_returns.std()
                max_drawdown = (cumulative_returns / cumulative_returns.cummax() - 1).min()
                win_rate = len(strategy_returns[strategy_returns > 0]) / len(strategy_returns)
                
                # ë§¤ë§¤ ì‹ í˜¸ í†µê³„
                signal_counts = signals.value_counts()
                total_signals = len(signals)
                
                metrics = {
                    'ëˆ„ì  ìˆ˜ìµë¥ ': total_return,
                    'ìƒ¤í”„ ë¹„ìœ¨': sharpe_ratio,
                    'ìµœëŒ€ ë‚™í­': max_drawdown,
                    'ìŠ¹ë¥ ': win_rate,
                    'ë§¤ìˆ˜ ì‹ í˜¸ ë¹„ìœ¨': signal_counts.get('BUY', 0) / total_signals,
                    'ë§¤ë„ ì‹ í˜¸ ë¹„ìœ¨': signal_counts.get('SELL', 0) / total_signals,
                    'ê´€ë§ ì‹ í˜¸ ë¹„ìœ¨': signal_counts.get('HOLD', 0) / total_signals,
                    'ì´ ê±°ë˜ íšŸìˆ˜': len(positions[positions != 0])
                }
                
                signal_metrics[name] = metrics
                
                # ìˆ˜ìµë¥  ê³¡ì„  ì‹œê°í™”
                fig = go.Figure()
                
                fig.add_trace(go.Scatter(
                    x=cumulative_returns.index,
                    y=cumulative_returns,
                    mode='lines',
                    name=f'{name} ì „ëµ ìˆ˜ìµë¥ ',
                    line=dict(width=2)
                ))
                
                fig.update_layout(
                    title=f'{name} ëª¨ë¸ì˜ ëˆ„ì  ìˆ˜ìµë¥ ',
                    xaxis_title='ë‚ ì§œ',
                    yaxis_title='ëˆ„ì  ìˆ˜ìµë¥ ',
                    height=500
                )
                
                st.plotly_chart(fig)
                
                # ì„±ê³¼ ì§€í‘œ í‘œì‹œ
                metrics_df = pd.DataFrame([metrics]).T
                metrics_df.columns = ['ê°’']
                
                # ì„±ê³¼ ì§€í‘œ í¬ë§·íŒ…
                formatted_metrics = metrics_df.copy()
                formatted_metrics.loc['ëˆ„ì  ìˆ˜ìµë¥ ', 'ê°’'] = f"{metrics['ëˆ„ì  ìˆ˜ìµë¥ ']*100:.2f}%"
                formatted_metrics.loc['ìƒ¤í”„ ë¹„ìœ¨', 'ê°’'] = f"{metrics['ìƒ¤í”„ ë¹„ìœ¨']:.2f}"
                formatted_metrics.loc['ìµœëŒ€ ë‚™í­', 'ê°’'] = f"{metrics['ìµœëŒ€ ë‚™í­']*100:.2f}%"
                formatted_metrics.loc['ìŠ¹ë¥ ', 'ê°’'] = f"{metrics['ìŠ¹ë¥ ']*100:.2f}%"
                formatted_metrics.loc['ë§¤ìˆ˜ ì‹ í˜¸ ë¹„ìœ¨', 'ê°’'] = f"{metrics['ë§¤ìˆ˜ ì‹ í˜¸ ë¹„ìœ¨']*100:.2f}%"
                formatted_metrics.loc['ë§¤ë„ ì‹ í˜¸ ë¹„ìœ¨', 'ê°’'] = f"{metrics['ë§¤ë„ ì‹ í˜¸ ë¹„ìœ¨']*100:.2f}%"
                formatted_metrics.loc['ê´€ë§ ì‹ í˜¸ ë¹„ìœ¨', 'ê°’'] = f"{metrics['ê´€ë§ ì‹ í˜¸ ë¹„ìœ¨']*100:.2f}%"
                formatted_metrics.loc['ì´ ê±°ë˜ íšŸìˆ˜', 'ê°’'] = f"{metrics['ì´ ê±°ë˜ íšŸìˆ˜']}"
                
                st.write(f"### {name} ëª¨ë¸ ì„±ê³¼ ì§€í‘œ")
                st.dataframe(formatted_metrics)
                
                # ë§¤ë§¤ ì‹ í˜¸ ë¶„í¬ ì‹œê°í™”
                fig_signals = go.Figure(data=[
                    go.Pie(
                        labels=['ë§¤ìˆ˜', 'ë§¤ë„', 'ê´€ë§'],
                        values=[
                            metrics['ë§¤ìˆ˜ ì‹ í˜¸ ë¹„ìœ¨'],
                            metrics['ë§¤ë„ ì‹ í˜¸ ë¹„ìœ¨'],
                            metrics['ê´€ë§ ì‹ í˜¸ ë¹„ìœ¨']
                        ],
                        hole=.3
                    )
                ])
                
                fig_signals.update_layout(
                    title=f'{name} ëª¨ë¸ì˜ ë§¤ë§¤ ì‹ í˜¸ ë¶„í¬',
                    height=400
                )
                
                st.plotly_chart(fig_signals)
            
            return signal_metrics
            
        except Exception as e:
            st.error(f"ì‹ í˜¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def plot_model_comparison(self):
        """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”"""
        try:
            # ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            for name in self.predictions.keys():
                # predictionsê°€ Seriesì¸ ê²½ìš° ì²˜ë¦¬
                if isinstance(self.predictions[name], pd.Series):
                    signals = self.predictions[name]
                else:
                    # predictionsê°€ ë‹¤ë¥¸ í˜•íƒœì¸ ê²½ìš° Seriesë¡œ ë³€í™˜
                    signals = pd.Series(self.predictions[name])
                
                metrics = {}
                
                # ë§¤ë§¤ í¬ì§€ì…˜ ì´ˆê¸°í™”
                positions = pd.Series(0, index=signals.index)
                positions.loc[signals == 'BUY'] = 1
                positions.loc[signals == 'SELL'] = -1
                
                # í•´ë‹¹ ê¸°ê°„ì˜ ìˆ˜ìµë¥  ê³„ì‚°
                period_returns = self.returns[signals.index]
                strategy_returns = positions * period_returns
                strategy_returns = strategy_returns.fillna(0)  # NaN ê°’ ì²˜ë¦¬
                
                # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
                cumulative_returns = (1 + strategy_returns).cumprod()
                
                # ì•ˆì „í•œ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
                try:
                    # ëˆ„ì  ìˆ˜ìµë¥ 
                    if len(cumulative_returns) > 0:
                        metrics['ëˆ„ì  ìˆ˜ìµë¥ '] = float(cumulative_returns.iloc[-1] - 1)
                    else:
                        metrics['ëˆ„ì  ìˆ˜ìµë¥ '] = 0.0
                    
                    # í‰ê·  ìˆ˜ìµë¥ 
                    metrics['í‰ê·  ìˆ˜ìµë¥ '] = float(strategy_returns.mean()) if len(strategy_returns) > 0 else 0.0
                    
                    # ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°
                    returns_std = float(strategy_returns.std())
                    returns_mean = float(strategy_returns.mean())
                    
                    if returns_std > 0 and not np.isnan(returns_std) and not np.isnan(returns_mean):
                        metrics['ìƒ¤í”„ ë¹„ìœ¨'] = float(np.sqrt(252) * returns_mean / returns_std)
                    else:
                        metrics['ìƒ¤í”„ ë¹„ìœ¨'] = 0.0
                    
                    # ìŠ¹ë¥  ê³„ì‚°
                    positive_returns = strategy_returns[strategy_returns > 0]
                    total_trades = len(strategy_returns[strategy_returns != 0])
                    
                    if total_trades > 0:
                        metrics['ìŠ¹ë¥ '] = float(len(positive_returns) / total_trades)
                    else:
                        metrics['ìŠ¹ë¥ '] = 0.0
                        
                    # ìµœëŒ€ ì†ì‹¤/ìˆ˜ìµ
                    metrics['ìµœëŒ€ ì†ì‹¤'] = float(strategy_returns.min()) if len(strategy_returns) > 0 else 0.0
                    metrics['ìµœëŒ€ ìˆ˜ìµ'] = float(strategy_returns.max()) if len(strategy_returns) > 0 else 0.0
                    
                except Exception as calc_error:
                    st.warning(f"{name} ëª¨ë¸ì˜ ì„±ê³¼ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(calc_error)}")
                    metrics = {
                        'ëˆ„ì  ìˆ˜ìµë¥ ': 0.0,
                        'í‰ê·  ìˆ˜ìµë¥ ': 0.0,
                        'ìƒ¤í”„ ë¹„ìœ¨': 0.0,
                        'ìŠ¹ë¥ ': 0.0,
                        'ìµœëŒ€ ì†ì‹¤': 0.0,
                        'ìµœëŒ€ ìˆ˜ìµ': 0.0
                    }
                
                # NaN ì²´í¬ ë° ì²˜ë¦¬
                for key in metrics:
                    if np.isnan(metrics[key]) or np.isinf(metrics[key]):
                        metrics[key] = 0.0
                
                self.performance_metrics[name] = metrics
            
            # ì„±ëŠ¥ ì§€í‘œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            metrics_df = pd.DataFrame.from_dict(self.performance_metrics, orient='index')
            
            # NaN ê°’ ì²˜ë¦¬
            metrics_df = metrics_df.fillna(0.0)
            
            # 1. ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ
            fig1 = go.Figure()
            for name in metrics_df.index:
                fig1.add_trace(
                    go.Bar(
                        name=name,
                        x=['ëˆ„ì  ìˆ˜ìµë¥ '],
                        y=[metrics_df.loc[name, 'ëˆ„ì  ìˆ˜ìµë¥ '] * 100],
                        text=[f"{metrics_df.loc[name, 'ëˆ„ì  ìˆ˜ìµë¥ ']*100:.2f}%"],
                        textposition='auto'
                    )
                )
            
            fig1.update_layout(
                title='ëª¨ë¸ë³„ ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ',
                yaxis_title='ìˆ˜ìµë¥  (%)',
                barmode='group',
                height=500
            )
            
            st.plotly_chart(fig1)
            
            # 2. ì„±ëŠ¥ ì§€í‘œ í¬ë§·íŒ… ë° í‘œì‹œ
            formatted_metrics = metrics_df.copy()
            formatted_metrics['ëˆ„ì  ìˆ˜ìµë¥ '] = formatted_metrics['ëˆ„ì  ìˆ˜ìµë¥ '].apply(lambda x: f"{x*100:.2f}%")
            formatted_metrics['í‰ê·  ìˆ˜ìµë¥ '] = formatted_metrics['í‰ê·  ìˆ˜ìµë¥ '].apply(lambda x: f"{x*100:.2f}%")
            formatted_metrics['ìŠ¹ë¥ '] = formatted_metrics['ìŠ¹ë¥ '].apply(lambda x: f"{x*100:.2f}%")
            formatted_metrics['ìƒ¤í”„ ë¹„ìœ¨'] = formatted_metrics['ìƒ¤í”„ ë¹„ìœ¨'].apply(lambda x: f"{x:.2f}")
            formatted_metrics['ìµœëŒ€ ì†ì‹¤'] = formatted_metrics['ìµœëŒ€ ì†ì‹¤'].apply(lambda x: f"{x*100:.2f}%")
            formatted_metrics['ìµœëŒ€ ìˆ˜ìµ'] = formatted_metrics['ìµœëŒ€ ìˆ˜ìµ'].apply(lambda x: f"{x*100:.2f}%")
            
            st.write("### ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ ë¹„êµ")
            st.dataframe(formatted_metrics)
            
            # 3. ìŠ¹ë¥ ê³¼ ìƒ¤í”„ ë¹„ìœ¨ ë¹„êµ
            fig2 = go.Figure()
            for name in metrics_df.index:
                fig2.add_trace(
                    go.Scatter(
                        x=[metrics_df.loc[name, 'ìŠ¹ë¥ ']],
                        y=[metrics_df.loc[name, 'ìƒ¤í”„ ë¹„ìœ¨']],
                        mode='markers+text',
                        name=name,
                        text=[name],
                        textposition="top center",
                        marker=dict(size=15)
                    )
                )
            
            fig2.update_layout(
                title='ìŠ¹ë¥  vs ìƒ¤í”„ ë¹„ìœ¨',
                xaxis_title='ìŠ¹ë¥ ',
                yaxis_title='ìƒ¤í”„ ë¹„ìœ¨',
                height=600,
                showlegend=False
            )
            
            st.plotly_chart(fig2)
            
            # 4. ëª¨ë¸ ìˆœìœ„ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
            metrics_df['ì¢…í•© ì ìˆ˜'] = (
                metrics_df['ëˆ„ì  ìˆ˜ìµë¥ '].fillna(0) * 0.4 +
                metrics_df['ìŠ¹ë¥ '].fillna(0) * 0.3 +
                (metrics_df['ìƒ¤í”„ ë¹„ìœ¨'].fillna(0) / 10) * 0.3
            )
            
            ranks_df = pd.DataFrame({
                'ëª¨ë¸': metrics_df.index,
                'ì¢…í•© ì ìˆ˜': metrics_df['ì¢…í•© ì ìˆ˜']
            }).sort_values('ì¢…í•© ì ìˆ˜', ascending=False)
            
            st.write("### ëª¨ë¸ ì¢…í•© ìˆœìœ„")
            st.dataframe(
                ranks_df.style.background_gradient(
                    cmap='YlOrRd',
                    subset=['ì¢…í•© ì ìˆ˜']
                ).format({'ì¢…í•© ì ìˆ˜': '{:.4f}'})
            )
            
            return self.performance_metrics
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.write("Error details:", str(e))
            return None

# ë©”ì¸ ë¶„ì„ ë¶€ë¶„ ìˆ˜ì •
if st.sidebar.button("ë¶„ì„ ì‹œì‘"):
    stock_data = get_stock_data(ticker, start_date, end_date)
    
    if stock_data is not None:
        with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
            try:
                # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                tech_analyzer = TechnicalAnalyzer(stock_data)
                
                # í™•ë¥ ì  ë¶„ì„
                prob_analyzer = ProbabilisticAnalyzer(tech_analyzer.data)
                
                # ëª¨ë¸ í•™ìŠµ
                if prob_analyzer.train_all_models():
                    # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„
                    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„")
                    prob_analyzer.compare_models()
                    
                    # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
                    st.subheader("ğŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
                    prob_analyzer.plot_feature_importance()
                    
                    # ROC ê³¡ì„  ë¶„ì„
                    st.subheader("ğŸ“‰ ROC ê³¡ì„  ë¶„ì„")
                    prob_analyzer.plot_roc_curves()
                    
                    # ëª¨ë¸ë³„ ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„
                    st.subheader("ğŸ¤– ëª¨ë¸ë³„ ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„")
                    model_analyzer = ModelSignalAnalyzer(prob_analyzer.models, tech_analyzer.data, prob_analyzer.predictions)
                    model_analyzer.analyze_signals()
                    
                    # ëª¨ë¸ ë¹„êµ ê²°ê³¼ í‘œì‹œ
                    fig, matrix_df = model_analyzer.plot_model_comparison()
                    
                    # ë§¤íŠ¸ë¦­ìŠ¤ í‘œì‹œ
                    st.write("### ëª¨ë¸ë³„ ë§¤ë§¤ ì‹ í˜¸ í™•ë¥ ")
                    st.dataframe(matrix_df.style.apply(lambda x: ['background-color: #e6ffe6' if v == 'BUY'
                                                                else 'background-color: #ffe6e6' if v == 'SELL'
                                                                else 'background-color: #f2f2f2'
                                                                for v in x], subset=['Current Signal']))
                    
                    # íˆíŠ¸ë§µ í‘œì‹œ
                    st.plotly_chart(fig)
                    
                    # ëª¨ë¸ ì•™ìƒë¸” ê¸°ë°˜ ìµœì¢… ì¶”ì²œ
                    current_signals = matrix_df['Current Signal'].value_counts()
                    st.write("### ëª¨ë¸ ì•™ìƒë¸” ê¸°ë°˜ ìµœì¢… ì¶”ì²œ")
                    
                    total_models = len(matrix_df)
                    buy_strength = current_signals.get('BUY', 0) / total_models * 100
                    sell_strength = current_signals.get('SELL', 0) / total_models * 100
                    hold_strength = current_signals.get('HOLD', 0) / total_models * 100
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ë§¤ìˆ˜ ì‹ í˜¸ ê°•ë„", f"{buy_strength:.1f}%")
                    with col2:
                        st.metric("ë§¤ë„ ì‹ í˜¸ ê°•ë„", f"{sell_strength:.1f}%")
                    with col3:
                        st.metric("ê´€ë§ ì‹ í˜¸ ê°•ë„", f"{hold_strength:.1f}%")
                    
                    # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœì¢… ì¶”ì²œ
                    weighted_signals = {}
                    for _, row in matrix_df.iterrows():
                        accuracy = float(row['Accuracy'].rstrip('%')) / 100
                        signal = row['Current Signal']
                        weighted_signals[signal] = weighted_signals.get(signal, 0) + accuracy
                    
                    max_signal = max(weighted_signals.items(), key=lambda x: x[1])
                    total_weight = sum(weighted_signals.values())
                    confidence = (max_signal[1] / total_weight) * 100
                    
                    signal_color = {
                        'BUY': 'green',
                        'SELL': 'red',
                        'HOLD': 'blue'
                    }
                    
                    st.markdown(f"### ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœì¢… ì¶”ì²œ: "
                              f"<span style='color: {signal_color[max_signal[0]]}'>{max_signal[0]}</span> "
                              f"(ì‹ ë¢°ë„: {confidence:.1f}%)", unsafe_allow_html=True)
                    
                    # ì„ í˜• íšŒê·€ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
                    prob_analyzer.plot_regression_analysis()
                    
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    else:
        st.error(
            "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
            "í‹°ì»¤ ì‹¬ë³¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        ) 

