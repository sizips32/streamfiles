import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV
)
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import (
    mean_squared_error,
    r2_score,
    accuracy_score,
    mean_absolute_error,
    roc_auc_score,
    confusion_matrix,
    precision_score,
    recall_score,
    f1_score,
    roc_curve
)
import plotly.graph_objects as go
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from xgboost import XGBRegressor, XGBClassifier
try:
    from lightgbm import LGBMRegressor, LGBMClassifier
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    st.warning("LightGBMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install lightgbm")
import plotly.express as px
import time
import sys
from tensorflow.keras.callbacks import EarlyStopping

# ì „ì—­ ë³€ìˆ˜ ì„¤ì •
XGBOOST_AVAILABLE = False

# XGBoost ê°€ìš©ì„± í™•ì¸
try:
    from xgboost import XGBClassifier
    XGBOOST_AVAILABLE = True
except ImportError:
    st.warning("XGBoostë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install xgboost")

# LightGBM ê°€ìš©ì„± í™•ì¸
try:
    from lightgbm import LGBMClassifier
    LIGHTGBM_AVAILABLE = True
except ImportError:
    st.warning("LightGBMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install lightgbm")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Financial Machine Learning App", layout="wide")
st.title("Financial Machine Learning Analysis")

# ëª¨ë¸ ì„¤ëª… ì„¹ì…˜
with st.expander("ğŸ“š ëª¨ë¸ ì„¤ëª… ë° íŒŒë¼ë¯¸í„° ê°€ì´ë“œ", expanded=True):
    st.markdown("""
    ### ğŸ¤– ëª¨ë¸ ì¢…ë¥˜ë³„ íŠ¹ì§•
    
    #### 1. Random Forest
    - **íŠ¹ì§•**: ì—¬ëŸ¬ ê°œì˜ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ì•™ìƒë¸”í•˜ëŠ” ëª¨ë¸
    - **ì¥ì **: ê³¼ì í•©ì— ê°•í•˜ê³ , íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŒ
    - **ë‹¨ì **: ëª¨ë¸ì´ ë³µì¡í•˜ê³  í•™ìŠµ/ì˜ˆì¸¡ ì‹œê°„ì´ ê¹€
    
    #### 2. ì„ í˜• íšŒê·€
    - **íŠ¹ì§•**: ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ë¥¼ ëª¨ë¸ë§
    - **ì¥ì **: í•´ì„ì´ ì‰½ê³  í•™ìŠµì´ ë¹ ë¦„
    - **ë‹¨ì **: ë¹„ì„ í˜• ê´€ê³„ë¥¼ í¬ì°©í•˜ê¸° ì–´ë ¤ì›€
    
    #### 3. LSTM
    - **íŠ¹ì§•**: ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì— íŠ¹í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸
    - **ì¥ì **: ì¥ê¸° ì˜ì¡´ì„±ì„ ì˜ í¬ì°©í•˜ê³  ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥
    - **ë‹¨ì **: ë§ì€ ë°ì´í„°ì™€ ê³„ì‚° ìì›ì´ í•„ìš”
    
    ### ğŸ“Š íŒŒë¼ë¯¸í„° ì„¤ëª…
    
    #### Random Forest íŒŒë¼ë¯¸í„°
    - **íŠ¸ë¦¬ ê°œìˆ˜**: ìƒì„±í•  ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ì˜ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì•ˆì •ì ì´ë‚˜ ëŠë ¤ì§)
    - **ìµœëŒ€ ê¹Šì´**: ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ (ê¹Šì„ìˆ˜ë¡ ê³¼ì í•© ìœ„í—˜)
    
    #### ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°
    - **íšŒê·€ ìœ í˜•**: 
        - Linear: ê¸°ë³¸ ì„ í˜• íšŒê·€
        - Ridge: L2 ê·œì œ ì ìš©
        - Lasso: L1 ê·œì œ ì ìš©
    - **ì•ŒíŒŒ**: ê·œì œ ê°•ë„ (ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ë‹¨ìˆœí•´ì§)
    
    #### LSTM íŒŒë¼ë¯¸í„°
    - **ì‹œí€€ìŠ¤ ê¸¸ì´**: ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„
    - **LSTM ìœ ë‹› ìˆ˜**: ëª¨ë¸ì˜ ë³µì¡ë„ ê²°ì •
    - **Dropout ë¹„ìœ¨**: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë¹„ìœ¨
    - **í•™ìŠµë¥ **: ëª¨ë¸ í•™ìŠµ ì†ë„ ì¡°ì ˆ
    
    ### ğŸ“ˆ ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
    
    #### ì„±ëŠ¥ ì§€í‘œ
    - **MSE (Mean Squared Error)**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ì œê³±í•œ í‰ê· 
        - ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        - ì‹¤ì œ ì£¼ê°€ ë‹¨ìœ„ì˜ ì œê³±
    - **RÂ² Score**: ëª¨ë¸ì´ ì„¤ëª…í•˜ëŠ” ë¶„ì‚°ì˜ ë¹„ìœ¨
        - 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
        - 0~1 ì‚¬ì´ì˜ ê°’
    
    #### ì‹œê°í™”
    - **íŠ¹ì„± ì¤‘ìš”ë„**: ê° ì…ë ¥ ë³€ìˆ˜ê°€ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥
    - **í•™ìŠµ ê³¡ì„ **: ëª¨ë¸ì˜ í•™ìŠµ ì§„í–‰ ìƒí™©
    - **ì˜ˆì¸¡ ê²°ê³¼**: ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²© ë¹„êµ
    """)

# ì‚¬ì´ë“œë°” íŒŒë¼ë¯¸í„° ì„¤ì •
st.sidebar.header("ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •")

# ì£¼ì‹ ì‹¬ë³¼ ì…ë ¥
ticker = st.sidebar.text_input("ì£¼ì‹ ì‹¬ë³¼ ì…ë ¥", "AAPL")

# ë‚ ì§œ ë²”ìœ„ ì„ íƒ
col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input("ì‹œì‘ì¼", datetime.now() - timedelta(days=365*3))
with col2:
    end_date = st.date_input("ì¢…ë£Œì¼", datetime.now())

# ëª¨ë¸ ì„ íƒ
model_type = st.sidebar.selectbox(
    "ëª¨ë¸ ì„ íƒ",
    ["Random Forest", "ì„ í˜• íšŒê·€", "LSTM", "XGBoost", "LightGBM"]
)

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹ ì˜µì…˜
enable_auto_tuning = st.sidebar.checkbox("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹", value=False)

# Random Forest íŒŒë¼ë¯¸í„°
if model_type == "Random Forest":
    st.sidebar.subheader("Random Forest íŒŒë¼ë¯¸í„°")
    n_estimators = st.sidebar.slider(
        "íŠ¸ë¦¬ ê°œìˆ˜ (n_estimators)", 
        min_value=10, 
        max_value=500, 
        value=100,
        help="ë” ë§ì€ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ ì•ˆì •ì„±ì´ í–¥ìƒë˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ì¦ê°€í•©ë‹ˆë‹¤."
    )
    
    max_depth = st.sidebar.slider(
        "ìµœëŒ€ ê¹Šì´ (max_depth)", 
        min_value=1, 
        max_value=50, 
        value=10,
        help="íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ë¥¼ ì œí•œí•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤."
    )

# ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°
elif model_type == "ì„ í˜• íšŒê·€":
    st.sidebar.subheader("ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°")
    regression_type = st.sidebar.selectbox(
        "íšŒê·€ ëª¨ë¸ ìœ í˜•",
        ["Linear", "Ridge", "Lasso"]
    )
    
    if regression_type in ["Ridge", "Lasso"]:
        alpha = st.sidebar.slider(
            "ì•ŒíŒŒ (ê·œì œ ê°•ë„)", 
            min_value=0.0, 
            max_value=10.0, 
            value=1.0,
            help="ë†’ì€ ê°’ì€ ë” ê°•í•œ ê·œì œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
        )

# LSTM íŒŒë¼ë¯¸í„°
elif model_type == "LSTM":
    st.sidebar.subheader("LSTM íŒŒë¼ë¯¸í„°")
    sequence_length = st.sidebar.slider(
        "ì‹œí€€ìŠ¤ ê¸¸ì´", 
        min_value=5, 
        max_value=60, 
        value=30,
        help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„°ì˜ ê¸°ê°„"
    )
    
    lstm_units = st.sidebar.slider(
        "LSTM ìœ ë‹› ìˆ˜", 
        min_value=32, 
        max_value=256, 
        value=128,
        help="ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."
    )
    
    dropout_rate = st.sidebar.slider(
        "Dropout ë¹„ìœ¨", 
        min_value=0.0, 
        max_value=0.5, 
        value=0.2,
        help="ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ dropout ë¹„ìœ¨"
    )
    
    learning_rate = st.sidebar.slider(
        "í•™ìŠµë¥ ", 
        min_value=0.0001, 
        max_value=0.01, 
        value=0.001,
        format="%.4f",
        help="ëª¨ë¸ì˜ í•™ìŠµ ì†ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤."
    )

# ê³µí†µ íŒŒë¼ë¯¸í„°
test_size = st.sidebar.slider(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 
    min_value=0.1, 
    max_value=0.4, 
    value=0.2,
    help="ì „ì²´ ë°ì´í„° ì¤‘ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ë¹„ìœ¨ì„ ì„¤ì •í•©ë‹ˆë‹¤."
)

# ë°ì´í„° ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def get_stock_data(ticker, start, end):
    try:
        data = yf.download(ticker, start=start, end=end)
        if data.empty:
            st.error(f"'{ticker}' ì‹¬ë³¼ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ì£¼ì‹ ì‹¬ë³¼ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return None
        data.reset_index(inplace=True)
        st.success(f"{ticker} ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ({len(data)} ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸)")
        return data
    except Exception as e:
        st.error(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.info("ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\n- ì¸í„°ë„· ì—°ê²° ìƒíƒœ\n- ì£¼ì‹ ì‹¬ë³¼ì˜ ì •í™•ì„±\n- ì„ íƒí•œ ë‚ ì§œ ë²”ìœ„ì˜ ìœ íš¨ì„±")
        return None

def validate_parameters(model_type, **params):
    """ëª¨ë¸ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬"""
    try:
        if model_type == "Random Forest":
            if params.get('n_estimators', 0) < 10:
                st.warning(
                    "íŠ¸ë¦¬ ê°œìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. "
                    "ìµœì†Œ 10ê°œ ì´ìƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                )
            if params.get('max_depth', 0) > 30:
                st.warning(
                    "íŠ¸ë¦¬ ê¹Šì´ê°€ ê¹ŠìŠµë‹ˆë‹¤. "
                    "ê³¼ì í•©ì˜ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤."
                )
        
        elif model_type == "LSTM":
            if params.get('sequence_length', 0) < 10:
                st.warning(
                    "ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. "
                    "ì˜ˆì¸¡ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
            if params.get('dropout_rate', 0) > 0.5:
                st.warning(
                    "Dropout ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. "
                    "í•™ìŠµì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
        
        return True
    except Exception as e:
        st.error(f"íŒŒë¼ë¯¸í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

# LSTM ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜
def prepare_lstm_data(data, sequence_length):
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data[['Close']])
    
    X, y = [], []
    for i in range(len(scaled_data) - sequence_length):
        X.append(scaled_data[i:(i + sequence_length), 0])
        y.append(scaled_data[i + sequence_length, 0])
    
    X = np.array(X)
    y = np.array(y)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    
    return X, y, scaler

def get_model_and_params(model_type):
    """ëª¨ë¸ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ë°˜í™˜"""
    if model_type == "Random Forest":
        model = RandomForestRegressor(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 10, 15],
            'min_samples_split': [2, 5, 10]
        }
    elif model_type == "XGBoost":
        model = XGBRegressor(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    elif model_type == "LightGBM":
        model = LGBMRegressor(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'num_leaves': [31, 62, 127],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    else:
        return None, None
    
    return model, param_grid

def auto_tune_model(model, param_grid, X_train, y_train):
    """GridSearchCVë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
    with st.spinner("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘..."):
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grid,
            cv=5,
            n_jobs=-1,
            scoring='neg_mean_squared_error'
        )
        grid_search.fit(X_train, y_train)
        
        st.success("ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        st.write("ìµœì  íŒŒë¼ë¯¸í„°:", grid_search.best_params_)
        st.write("ìµœì  ì ìˆ˜:", -grid_search.best_score_)
        
        return grid_search.best_estimator_

def plot_feature_importance(model, feature_names):
    """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
    if hasattr(model, 'feature_importances_'):
        importances = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        fig = px.bar(
            importances,
            x='feature',
            y='importance',
            title='íŠ¹ì„± ì¤‘ìš”ë„'
        )
        st.plotly_chart(fig)
    else:
        st.info("ì´ ëª¨ë¸ì€ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def plot_learning_curves(history):
    """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
    if history is not None and hasattr(history, 'history'):
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                y=history.history['loss'],
                name='Train Loss'
            )
        )
        if 'val_loss' in history.history:
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'],
                    name='Validation Loss'
                )
            )
        fig.update_layout(
            title='í•™ìŠµ ê³¡ì„ ',
            xaxis_title='Epoch',
            yaxis_title='Loss'
        )
        st.plotly_chart(fig)

def evaluate_model(model, X_test, y_test, scaler=None):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    start_time = time.time()
    y_pred = model.predict(X_test)
    inference_time = time.time() - start_time
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = {
        'MAE': mean_absolute_error(y_test, y_pred),
        'MSE': mean_squared_error(y_test, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
        'R2 Score': r2_score(y_test, y_pred),
        'ì¶”ë¡  ì‹œê°„': f"{inference_time:.4f}ì´ˆ"
    }
    
    # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    metrics_df = pd.DataFrame([metrics]).T
    metrics_df.columns = ['ê°’']
    st.table(metrics_df)
    
    # ì˜ˆì¸¡ vs ì‹¤ì œ ê·¸ë˜í”„
    fig = go.Figure()
    fig.add_trace(
        go.Scatter(
            x=y_test,
            y=y_pred,
            mode='markers',
            name='ì˜ˆì¸¡ vs ì‹¤ì œ',
            marker=dict(color='blue', opacity=0.5)
        ))
    fig.add_trace(
        go.Scatter(
            x=[y_test.min(), y_test.max()],
            y=[y_test.min(), y_test.max()],
            mode='lines',
            name='ì´ìƒì ì¸ ì˜ˆì¸¡',
            line=dict(color='red', dash='dash')
        ))
    fig.update_layout(
        title='ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ë¹„êµ',
        xaxis_title='ì‹¤ì œ ê°’',
        yaxis_title='ì˜ˆì¸¡ ê°’'
    )
    st.plotly_chart(fig)
    
    return metrics

# ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€
def calculate_technical_indicators(data):
    """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
    # RSI
    delta = data['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    data['RSI'] = 100 - (100 / (1 + rs))
    
    # MACD
    exp1 = data['Close'].ewm(span=12, adjust=False).mean()
    exp2 = data['Close'].ewm(span=26, adjust=False).mean()
    data['MACD'] = exp1 - exp2
    data['Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()
    
    # Bollinger Bands
    data['MA20'] = data['Close'].rolling(window=20).mean()
    data['BB_upper'] = data['MA20'] + 2 * data['Close'].rolling(window=20).std()
    data['BB_lower'] = data['MA20'] - 2 * data['Close'].rolling(window=20).std()
    
    return data

# í™•ë¥ ì  ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤ ì¶”ê°€
class ProbabilisticPredictor:
    def __init__(self, data, sequence_length=30):
        self.data = data
        self.sequence_length = sequence_length
        self.models = []
        self.prepare_data()
        
    def prepare_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # íŠ¹ì„± ìƒì„±
        self.data['Returns'] = self.data['Close'].pct_change()
        self.data['Volatility'] = self.data['Returns'].rolling(window=20).std()
        self.data['MA20'] = self.data['Close'].rolling(window=20).mean()
        
        # NaN ì œê±°
        self.data.dropna(inplace=True)
        
        # ì…ë ¥ íŠ¹ì„± ì„ íƒ
        self.features = ['Open', 'High', 'Low', 'Volume', 'Returns', 'Volatility', 'MA20']
        self.X = self.data[self.features]
        self.y = self.data['Close']
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        self.scaler = MinMaxScaler()
        self.X_scaled = self.scaler.fit_transform(self.X)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_size = int(len(self.X_scaled) * 0.8)
        self.X_train = self.X_scaled[:train_size]
        self.X_test = self.X_scaled[train_size:]
        self.y_train = self.y[:train_size]
        self.y_test = self.y[train_size:]
    
    def train_ensemble(self):
        """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ"""
        self.models = []
        base_models = [
            RandomForestRegressor(n_estimators=100, random_state=42),
            XGBRegressor(random_state=42)
        ]
        
        if LIGHTGBM_AVAILABLE:
            base_models.append(LGBMRegressor(random_state=42))
        
        for model in base_models:
            model.fit(self.X_train, self.y_train)
            self.models.append(model)
        
        return self.models
    
    def predict_probability(self, X=None):
        """í™•ë¥ ì  ì˜ˆì¸¡ ìˆ˜í–‰"""
        if X is None:
            X = self.X_test
            
        if len(self.models) == 0:
            self.train_ensemble()
        
        predictions = []
        for model in self.models:
            pred = model.predict(X)
            predictions.append(pred)
        
        predictions = np.array(predictions)
        mean_pred = np.mean(predictions, axis=0)
        std_pred = np.std(predictions, axis=0)
        
        return mean_pred, std_pred

# íˆ¬ì ì‹ í˜¸ ìƒì„± í•¨ìˆ˜ ì¶”ê°€
def generate_trading_signals(data, pred_mean, pred_std):
    """ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ì‹ í˜¸ ìƒì„±"""
    signals = pd.DataFrame(index=data.index[-len(pred_mean):])  # ìˆ˜ì •ëœ ë¶€ë¶„
    
    # ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ì‹ í˜¸
    signals['RSI_signal'] = np.where(data['RSI'].iloc[-len(pred_mean):] < 30, 1, 
                                   np.where(data['RSI'].iloc[-len(pred_mean):] > 70, -1, 0))
    
    signals['MACD_signal'] = np.where(data['MACD'].iloc[-len(pred_mean):] > data['Signal'].iloc[-len(pred_mean):], 1, 
                                     np.where(data['MACD'].iloc[-len(pred_mean):] < data['Signal'].iloc[-len(pred_mean):], -1, 0))
    
    # ë³¼ë¦°ì € ë°´ë“œ ê¸°ë°˜ ì‹ í˜¸
    signals['BB_signal'] = np.where(data['Close'].iloc[-len(pred_mean):] < data['BB_lower'].iloc[-len(pred_mean):], 1,
                                   np.where(data['Close'].iloc[-len(pred_mean):] > data['BB_upper'].iloc[-len(pred_mean):], -1, 0))
    
    # í™•ë¥ ì  ì˜ˆì¸¡ ê¸°ë°˜ ì‹ í˜¸
    current_price = data['Close'].iloc[-len(pred_mean):]
    confidence_interval = 1.96 * pred_std
    
    signals['Pred_signal'] = np.where(pred_mean - confidence_interval > current_price, 1,
                                     np.where(pred_mean + confidence_interval < current_price, -1, 0))
    
    # ì¢…í•© ì‹ í˜¸
    signals['Final_signal'] = signals.mean(axis=1)
    
    return signals

# ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€
def calculate_risk_metrics(data, signals):
    """ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì§€í‘œ ê³„ì‚°"""
    risk_metrics = {}
    
    # ë³€ë™ì„± (20ì¼)
    volatility = data['Close'].pct_change().rolling(20).std() * np.sqrt(252)
    risk_metrics['Volatility'] = volatility.iloc[-1]  # ìˆ˜ì •ëœ ë¶€ë¶„
    
    # ìƒ¤í”„ ë¹„ìœ¨
    returns = data['Close'].pct_change()
    risk_free_rate = 0.02  # ì—°ê°„ ê¸°ì¤€
    excess_returns = returns - risk_free_rate/252
    risk_metrics['Sharpe_ratio'] = (np.sqrt(252) * excess_returns.mean() / returns.std())
    
    # ìµœëŒ€ ë‚™í­
    rolling_max = data['Close'].rolling(252, min_periods=1).max()
    drawdown = (data['Close'] - rolling_max) / rolling_max
    risk_metrics['Max_drawdown'] = drawdown.min()
    
    return risk_metrics

class TechnicalAnalyzer:
    def __init__(self, data):
        self.data = data
        self.features = []
        self.calculate_indicators()
        
    def calculate_indicators(self):
        """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        df = self.data.copy()
        
        # ê¸°ë³¸ ì´ë™í‰ê· 
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['SMA_5'] = df['Close'].rolling(window=5).mean()
        df['SMA_20'] = df['Close'].rolling(window=20).mean()
        df['SMA_60'] = df['Close'].rolling(window=60).mean()
        
        # RSI
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['Close'].ewm(span=12, adjust=False).mean()
        exp2 = df['Close'].ewm(span=26, adjust=False).mean()
        df['MACD'] = exp1 - exp2
        df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        
        # ë³¼ë¦°ì € ë°´ë“œ
        df['BB_middle'] = df['Close'].rolling(window=20).mean()
        bb_std = df['Close'].rolling(window=20).std()
        df['BB_upper'] = df['BB_middle'] + (bb_std * 2)
        df['BB_lower'] = df['BB_middle'] - (bb_std * 2)
        df['BB_Width'] = (df['BB_upper'] - df['BB_lower']) / df['BB_middle']
        
        # ëª¨ë©˜í…€ ì§€í‘œ
        df['ROC'] = df['Close'].pct_change(periods=12) * 100
        df['MOM'] = df['Close'].diff(periods=10)
        
        # ë³€ë™ì„± ì§€í‘œ
        df['ATR'] = self.calculate_atr(df)
        
        # ê±°ë˜ëŸ‰ ì§€í‘œ
        df['OBV'] = self.calculate_obv(df)
        df['Volume_MA'] = df['Volume'].rolling(window=20).mean()
        
        # ì¶”ê°€ íŒŒìƒ ì§€í‘œ
        df['Price_Change'] = df['Close'].pct_change()
        df['Volatility'] = df['Price_Change'].rolling(window=20).std()
        
        # NaN ê°’ ì²˜ë¦¬
        df.fillna(method='bfill', inplace=True)
        df.fillna(method='ffill', inplace=True)
        
        self.data = df
        self.features = [
            'SMA_5', 'SMA_20', 'SMA_60', 'RSI', 'MACD', 'Signal',
            'BB_Width', 'ROC', 'MOM', 'ATR', 'OBV', 'Volume_MA',
            'Price_Change', 'Volatility', 'BB_upper', 'BB_lower'
        ]
        
    def calculate_atr(self, df):
        """ATR(Average True Range) ê³„ì‚°"""
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        return true_range.rolling(14).mean()
    
    def calculate_obv(self, df):
        """OBV(On Balance Volume) ê³„ì‚°"""
        obv = np.zeros(len(df))
        for i in range(1, len(df)):
            if df['Close'].iloc[i] > df['Close'].iloc[i-1]:
                obv[i] = obv[i-1] + df['Volume'].iloc[i]
            elif df['Close'].iloc[i] < df['Close'].iloc[i-1]:
                obv[i] = obv[i-1] - df['Volume'].iloc[i]
            else:
                obv[i] = obv[i-1]
        return obv
    
    def get_features(self):
        """ë¶„ì„ì— ì‚¬ìš©í•  íŠ¹ì„± ë°˜í™˜"""
        return self.data[self.features]

class ProbabilisticAnalyzer:
    def __init__(self, data, test_size=0.2, sequence_length=10):
        self.data = data
        self.test_size = test_size
        self.sequence_length = sequence_length
        self.models = {}
        self.predictions = {}
        self.feature_importance = {}
        self.prepare_data()
    
    def prepare_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„"""
        try:
            # ê¸°ì¡´ ë°ì´í„° ì¤€ë¹„
            self.feature_names = [col for col in self.data.columns 
                                if col not in ['Date', 'Target', 'Label', 'Close']]
            
            self.data['Target'] = self.data['Close'].shift(-1) / self.data['Close'] - 1
            self.data['Label'] = np.where(self.data['Target'] > 0, 1, 0)
            self.data.dropna(inplace=True)
            
            # ìŠ¤ì¼€ì¼ë§
            self.scaler = MinMaxScaler()
            scaled_features = self.scaler.fit_transform(self.data[self.feature_names])
            
            # ë°ì´í„° ë¶„í• 
            train_size = int(len(scaled_features) * (1 - self.test_size))
            
            self.X_train = scaled_features[:train_size]
            self.X_test = scaled_features[train_size:]
            self.y_train = self.data['Label'].values[:train_size]
            self.y_test = self.data['Label'].values[train_size:]
            
            # LSTMìš© ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„
            self.X_train_seq = self.create_sequences(self.X_train)
            self.X_test_seq = self.create_sequences(self.X_test)
            self.y_train_seq = self.y_train[self.sequence_length:]
            self.y_test_seq = self.y_test[self.sequence_length:]
            
        except Exception as e:
            st.error(f"ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def create_sequences(self, X):
        """LSTMì„ ìœ„í•œ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
        sequences = []
        for i in range(len(X) - self.sequence_length):
            sequences.append(X[i:(i + self.sequence_length)])
        return np.array(sequences)
    
    def build_lstm_model(self):
        """LSTM ëª¨ë¸ êµ¬ì¶•"""
        model = Sequential([
            LSTM(50, return_sequences=True, input_shape=(self.sequence_length, len(self.feature_names))),
            Dropout(0.2),
            LSTM(50),
            Dropout(0.2),
            Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def train_models(self):
        """ëª¨ë“  ëª¨ë¸ í•™ìŠµ"""
        try:
            # Random Forest
            rf_model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )
            rf_model.fit(self.X_train, self.y_train)
            self.models['Random Forest'] = rf_model
            self.predictions['Random Forest'] = rf_model.predict(self.X_test)
            self.feature_importance['Random Forest'] = pd.Series(
                rf_model.feature_importances_,
                index=self.feature_names
            ).sort_values(ascending=False)
            
            # ì„ í˜• íšŒê·€
            lr_model = LinearRegression()
            lr_model.fit(self.X_train, self.y_train)
            self.models['Linear'] = lr_model
            self.predictions['Linear'] = lr_model.predict(self.X_test)
            self.feature_importance['Linear'] = pd.Series(
                np.abs(lr_model.coef_),
                index=self.feature_names
            ).sort_values(ascending=False)
            
            # XGBoost
            xgb_model = XGBRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
            xgb_model.fit(self.X_train, self.y_train)
            self.models['XGBoost'] = xgb_model
            self.predictions['XGBoost'] = xgb_model.predict(self.X_test)
            self.feature_importance['XGBoost'] = pd.Series(
                xgb_model.feature_importances_,
                index=self.feature_names
            ).sort_values(ascending=False)
            
            # LightGBM
            lgb_model = LGBMRegressor(
                n_estimators=100,
                learning_rate=0.1,
                num_leaves=31,
                random_state=42
            )
            lgb_model.fit(self.X_train, self.y_train)
            self.models['LightGBM'] = lgb_model
            self.predictions['LightGBM'] = lgb_model.predict(self.X_test)
            self.feature_importance['LightGBM'] = pd.Series(
                lgb_model.feature_importances_,
                index=self.feature_names
            ).sort_values(ascending=False)
            
            # LSTM
            lstm_model = self.build_lstm_model()
            early_stopping = EarlyStopping(
                monitor='val_loss',
                patience=5,
                restore_best_weights=True
            )
            
            history = lstm_model.fit(
                self.X_train_seq,
                self.y_train_seq,
                epochs=50,
                batch_size=32,
                validation_split=0.2,
                callbacks=[early_stopping],
                verbose=0
            )
            
            self.models['LSTM'] = lstm_model
            self.predictions['LSTM'] = lstm_model.predict(self.X_test_seq).flatten()
            
            # í•™ìŠµ ê²°ê³¼ ìš”ì•½
            st.success("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
            st.write("### ëª¨ë¸ë³„ í•™ìŠµ ì™„ë£Œ ìƒíƒœ")
            for model_name in self.models.keys():
                st.write(f"âœ… {model_name}")
            
            return True
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def compare_models(self):
        """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„"""
        try:
            metrics = {}
            
            for name, predictions in self.predictions.items():
                # LSTMê³¼ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì˜ ë°ì´í„° ê¸¸ì´ ë§ì¶”ê¸°
                if name == 'LSTM':
                    y_true = self.y_test_seq
                    predictions = predictions[-len(y_true):]  # ì˜ˆì¸¡ê°’ ê¸¸ì´ ì¡°ì •
                else:
                    y_true = self.y_test[-len(self.y_test_seq):]  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸¸ì´ ì¡°ì •
                    predictions = predictions[-len(self.y_test_seq):]  # ì˜ˆì¸¡ê°’ ê¸¸ì´ ì¡°ì •
                
                # íšŒê·€ ì§€í‘œ
                mse = mean_squared_error(y_true, predictions)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(y_true, predictions)
                r2 = r2_score(y_true, predictions)
                
                metrics[name] = {
                    'MSE': mse,
                    'RMSE': rmse,
                    'MAE': mae,
                    'R2 Score': r2
                }
            
            # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            metrics_df = pd.DataFrame(metrics).T
            
            # ê²°ê³¼ í‘œì‹œ
            st.write("### ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ")
            st.dataframe(metrics_df.style.format({
                'MSE': '{:.6f}',
                'RMSE': '{:.6f}',
                'MAE': '{:.6f}',
                'R2 Score': '{:.6f}'
            }))
            
            # ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”
            fig = go.Figure()
            
            for metric in metrics_df.columns:
                fig.add_trace(go.Bar(
                    name=metric,
                    x=metrics_df.index,
                    y=metrics_df[metric],
                    text=metrics_df[metric].round(4),
                    textposition='auto',
                ))
            
            fig.update_layout(
                title='ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ ë¹„êµ',
                barmode='group',
                height=500
            )
            st.plotly_chart(fig)
            
            # ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’ ì‚°ì ë„
            for name, predictions in self.predictions.items():
                if name == 'LSTM':
                    y_true = self.y_test_seq
                    pred = predictions[-len(y_true):]
                else:
                    y_true = self.y_test[-len(self.y_test_seq):]
                    pred = predictions[-len(self.y_test_seq):]
                
                fig = px.scatter(
                    x=y_true,
                    y=pred,
                    title=f'{name} - ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’',
                    labels={'x': 'ì‹¤ì œê°’', 'y': 'ì˜ˆì¸¡ê°’'}
                )
                
                # ì´ìƒì ì¸ ì˜ˆì¸¡ì„  ì¶”ê°€
                min_val = min(y_true.min(), pred.min())
                max_val = max(y_true.max(), pred.max())
                fig.add_trace(
                    go.Scatter(
                        x=[min_val, max_val],
                        y=[min_val, max_val],
                        mode='lines',
                        name='ì´ìƒì ì¸ ì˜ˆì¸¡',
                        line=dict(dash='dash', color='red')
                    )
                )
                
                fig.update_layout(
                    xaxis_title='ì‹¤ì œê°’',
                    yaxis_title='ì˜ˆì¸¡ê°’',
                    height=500
                )
                st.plotly_chart(fig)
            
            return metrics_df
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.DataFrame()
    
    def plot_feature_importance(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
        try:
            if not self.feature_importance:
                st.warning("íŠ¹ì„± ì¤‘ìš”ë„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            for name, importance in self.feature_importance.items():
                top_features = importance.head(10)
                
                fig = px.bar(
                    x=top_features.values,
                    y=top_features.index,
                    orientation='h',
                    title=f'{name} ëª¨ë¸ì˜ ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±'
                )
                
                fig.update_layout(
                    xaxis_title='ì¤‘ìš”ë„',
                    yaxis_title='íŠ¹ì„±',
                    height=400
                )
                
                st.plotly_chart(fig)
                
        except Exception as e:
            st.error(f"íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def plot_roc_curves(self):
        """ëª¨ë¸ë³„ ROC ê³¡ì„  ì‹œê°í™”"""
        try:
            fig = go.Figure()
            
            for name, predictions in self.predictions.items():
                # LSTMê³¼ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì˜ ë°ì´í„° ê¸¸ì´ ë§ì¶”ê¸°
                if name == 'LSTM':
                    y_true = self.y_test_seq
                    pred = predictions[-len(y_true):]
                else:
                    y_true = self.y_test[-len(self.y_test_seq):]
                    pred = predictions[-len(self.y_test_seq):]
                
                # ROC ê³¡ì„  ê³„ì‚°
                fpr, tpr, _ = roc_curve(y_true, pred)
                auc_score = roc_auc_score(y_true, pred)
                
                # ROC ê³¡ì„  ì¶”ê°€
                fig.add_trace(
                    go.Scatter(
                        x=fpr,
                        y=tpr,
                        name=f'{name} (AUC = {auc_score:.3f})',
                        mode='lines'
                    )
                )
            
            # ëŒ€ê°ì„  ì¶”ê°€ (ëœë¤ ì˜ˆì¸¡ ê¸°ì¤€ì„ )
            fig.add_trace(
                go.Scatter(
                    x=[0, 1],
                    y=[0, 1],
                    name='Random',
                    mode='lines',
                    line=dict(dash='dash', color='gray')
                )
            )
            
            # ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig.update_layout(
                title='ROC ê³¡ì„  ë¹„êµ',
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                width=700,
                height=500,
                showlegend=True,
                legend=dict(
                    yanchor="bottom",
                    y=0.01,
                    xanchor="right",
                    x=0.99
                )
            )
            
            st.plotly_chart(fig)
            
            # AUC ì ìˆ˜ í‘œ ì¶”ê°€
            auc_scores = {}
            for name, predictions in self.predictions.items():
                if name == 'LSTM':
                    y_true = self.y_test_seq
                    pred = predictions[-len(y_true):]
                else:
                    y_true = self.y_test[-len(self.y_test_seq):]
                    pred = predictions[-len(self.y_test_seq):]
                
                auc_scores[name] = roc_auc_score(y_true, pred)
            
            auc_df = pd.DataFrame.from_dict(auc_scores, orient='index', columns=['AUC Score'])
            st.write("### AUC ì ìˆ˜ ë¹„êµ")
            st.dataframe(auc_df.style.format({'AUC Score': '{:.4f}'}))
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í•˜ì´ë¼ì´íŠ¸
            best_model = auc_df['AUC Score'].idxmax()
            st.success(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model} (AUC = {auc_df.loc[best_model, 'AUC Score']:.4f})")
            
        except Exception as e:
            st.error(f"ROC ê³¡ì„  ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("""
            ROC ê³¡ì„  ìƒì„± ì‹¤íŒ¨ ì›ì¸:
            1. ë°ì´í„° í˜•ì‹ ë¶ˆì¼ì¹˜
            2. ì˜ˆì¸¡ê°’ ë²”ìœ„ ë¬¸ì œ
            3. í´ë˜ìŠ¤ ë¶ˆê· í˜•
            
            í•´ê²° ë°©ì•ˆ:
            1. ë°ì´í„° ì „ì²˜ë¦¬ í™•ì¸
            2. ì˜ˆì¸¡ê°’ ì •ê·œí™” ê²€í† 
            3. í´ë˜ìŠ¤ ê· í˜• ì¡°ì •
            """)

# ë©”ì¸ ë¶„ì„ ë¶€ë¶„ ìˆ˜ì •
if st.sidebar.button("ë¶„ì„ ì‹œì‘"):
    stock_data = get_stock_data(ticker, start_date, end_date)
    
    if stock_data is not None:
        with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
            try:
                # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                tech_analyzer = TechnicalAnalyzer(stock_data)
                
                # í™•ë¥ ì  ë¶„ì„
                prob_analyzer = ProbabilisticAnalyzer(tech_analyzer.data)
                
                # ëª¨ë¸ í•™ìŠµ
                if prob_analyzer.train_models():
                    # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„
                    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„")
                    prob_analyzer.compare_models()
                    
                    # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
                    st.subheader("ğŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
                    prob_analyzer.plot_feature_importance()
                    
                    # ROC ê³¡ì„  ë¶„ì„
                    st.subheader("ğŸ“‰ ROC ê³¡ì„  ë¶„ì„")
                    prob_analyzer.plot_roc_curves()
                    
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.info("""
                ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ì œì•ˆ:
                1. ë°ì´í„° í˜•ì‹ í™•ì¸
                2. ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„° í™•ë³´
                3. ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¡°ì •
                """)
    else:
        st.error(
            "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
            "í‹°ì»¤ ì‹¬ë³¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        ) 

