import warnings

# FutureWarning ë¬´ì‹œ
warnings.simplefilter(action='ignore', category=FutureWarning)

import streamlit as st
import yfinance as yf
import pandas as pd
from pypfopt import (
    EfficientFrontier, risk_models, expected_returns,
    BlackLittermanModel, HRPOpt
)

st.title("Hedge Fund Portfolio Optimization")

# User input
tickers = st.text_input(
    "Enter tickers (comma-separated):",
    "034950.KS, 000270.KS, 000815.KS, 115570.KQ, 053800.KQ, 001840.KQ, 003690.KS, 049430.KS, 034950.KQ, 024940.KQ, 004060.KS"
)
start_date = st.date_input("Start date", value=pd.to_datetime("2020-01-01"))
end_date = st.date_input("End date", value=pd.to_datetime("2025-1-31"))

# User input for market outlook
market_outlook = st.selectbox(
    "Select long-term economic outlook:",
    options=["Neutral", "Positive", "Negative"]
)

# Sidebar for individual asset outlook
st.sidebar.subheader("Individual Asset Outlook")
st.sidebar.write("ê° ìì‚°ì˜ ê¸°ëŒ€ ìˆ˜ìµë¥  ì¡°ì •ì€ í•´ë‹¹ ìì‚°ì˜ ë¯¸ë˜ ìˆ˜ìµë¥ ì— ëŒ€í•œ ê°œì¸ì ì¸ ì „ë§ì„ ë°˜ì˜í•©ë‹ˆë‹¤. "
                 "ì˜ˆë¥¼ ë“¤ì–´, 1.1ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ìì‚°ì˜ ê¸°ëŒ€ ìˆ˜ìµë¥ ì´ 10% ì¦ê°€í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.")
individual_outlook = {}
for ticker in tickers.split(","):
    individual_outlook[ticker.strip()] = st.sidebar.number_input(
        f"Expected return adjustment for {ticker.strip()} "
        "(e.g., 1.1 for +10%, 0.9 for -10%)",
        value=1.0
    )

# Fetch data
if st.button("Fetch Data and Optimize"):
    tickers_list = [ticker.strip() for ticker in tickers.split(",")]

    try:
        data = yf.download(tickers_list, start=start_date,
                           end=end_date)['Close']
        if data.empty:
            st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì…ë ¥í•œ í‹°ì»¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            # Calculate daily returns
            returns = data.pct_change(fill_method=None).dropna()

            # Calculate cumulative returns
            cumulative_returns = (1 + returns).cumprod() - 1

            st.write("Cumulative Returns")
            st.line_chart(cumulative_returns)

            # Calculate expected returns and sample covariance
            mu = expected_returns.mean_historical_return(data)
            S = risk_models.sample_cov(data)

            # Ensure covariance matrix is symmetric
            S = (S + S.T) / 2

            # Optimization method selection
            methods = [
                "Equal Weight", "Maximum Sharpe Ratio", "Minimum Volatility",
                "Risk Parity", "Black-Litterman"
            ]
            selected_methods = st.multiselect(
                "Select optimization methods",
                methods,
                default=methods
            )

            results = {}
            
            if "Equal Weight" in selected_methods:
                n = len(tickers_list)
                weights = {ticker: 1/n for ticker in tickers_list}
                results["Equal Weight"] = weights

            if "Maximum Sharpe Ratio" in selected_methods:
                ef = EfficientFrontier(mu, S)
                weights = ef.max_sharpe()
                cleaned_weights = ef.clean_weights()
                results["Maximum Sharpe Ratio"] = cleaned_weights

            if "Minimum Volatility" in selected_methods:
                ef = EfficientFrontier(mu, S)
                weights = ef.min_volatility()
                cleaned_weights = ef.clean_weights()
                results["Minimum Volatility"] = cleaned_weights

            if "Risk Parity" in selected_methods:
                hrp = HRPOpt(returns)
                weights = hrp.optimize()
                results["Risk Parity"] = weights

            if "Black-Litterman" in selected_methods:
                market_caps = yf.download(
                    tickers_list, start=start_date, end=end_date
                )['Close'].iloc[-1]
                mcaps = market_caps / market_caps.sum()

                # Check if mu is valid
                if mu is not None and not mu.empty:
                    viewdict = {
                        ticker: mu[ticker] * individual_outlook[ticker]
                        for ticker in tickers_list
                    }

                    bl = BlackLittermanModel(S, pi=mu, absolute_views=viewdict)
                    bl_returns = bl.bl_returns()
                    ef = EfficientFrontier(bl_returns, S)
                    weights = ef.max_sharpe()
                    cleaned_weights = ef.clean_weights()
                    results["Black-Litterman"] = cleaned_weights
                else:
                    st.error(
                        "Expected returns (mu) could not be calculated. "
                        "Please check the input data."
                    )

            # Visualize results
            for method, weights in results.items():
                st.subheader(method)
                weights_df = pd.DataFrame(
                    list(weights.items()),
                    columns=['Asset', 'Weight']
                )
                weights_df['Weight'] = weights_df['Weight'] * 100
                st.write(
                    weights_df.to_html(
                        index=False,
                        float_format=lambda x: f'{x:.2f}%'
                    ),
                    unsafe_allow_html=True
                )

                # Use Streamlit's bar_chart for visualization
                st.bar_chart(weights_df.set_index('Asset'))

            # Generate results
            if results:
                st.subheader("Optimization Results")
                for method, weights in results.items():
                    # Method ì´ë¦„ì„ ê²€ì •ìƒ‰ ë³¼ë“œì²´ë¡œ í‘œì‹œí•˜ê³  ë°‘ì¤„ ì¶”ê°€
                    st.markdown(
                        f"<span style='color:black; font-size:24px; font-weight:bold; "
                        "text-decoration: underline;'>{method} Asset Allocation:</span>",
                        unsafe_allow_html=True
                    )

                    weights_df = pd.DataFrame(
                        list(weights.items()),
                        columns=['Asset', 'Weight']
                    )
                    weights_df['Weight'] = weights_df['Weight'] * 100

                    # ìƒìœ„ ë¹„ì¤‘ 2ê°œ ìƒ‰ìƒ í‘œì‹œ ë° ë³¼ë“œì²´ ì ìš©
                    top_weights = weights_df.nlargest(2, 'Weight')
                    weights_df['Weight'] = weights_df['Weight'].apply(
                        lambda x: f"{x:.2f}%")  # ë¹„ì¤‘ í¬ë§·íŒ…

                    # ê°€ë¡œ í˜•íƒœë¡œ í…Œì´ë¸” í‘œì‹œ
                    weights_df = weights_df.set_index('Asset').T  # ì „ì¹˜í•˜ì—¬ ê°€ë¡œ í˜•íƒœë¡œ ë³€ê²½
                    
                    # map ëŒ€ì‹  applymap ì‚¬ìš©
                    def style_top_weights(val):
                        return 'color: red; font-weight: bold;' if val in top_weights['Weight'].values else ''
                    
                    styled_weights_df = weights_df.style.applymap(
                        style_top_weights,
                        subset=top_weights['Asset'].tolist()
                    )

                    st.write(styled_weights_df)  # ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ

    except Exception as e:
        st.error(f"ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# íˆ¬ì ì „ëµ ì„¤ëª…ì„ expanderë¡œ ë³€ê²½
with st.expander("ğŸ“š í¬íŠ¸í´ë¦¬ì˜¤ íˆ¬ì ì „ëµ ì„¤ëª…"):
    st.markdown("""
    #### ê° í¬íŠ¸í´ë¦¬ì˜¤ íˆ¬ì ì „ëµì— ëŒ€í•œ ì„¤ëª…ê³¼ ì ìš© ë°©ë²•ì„ ì•„ë˜ì— ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.
    
    1. **Equal Weight (ë™ì¼ ë¹„ì¤‘)**
    - ì„¤ëª…: ëª¨ë“  ìì‚°ì— ë™ì¼í•œ ë¹„ì¤‘ì„ í• ë‹¹í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì´ë©°, íŠ¹ì • ìì‚°ì— ëŒ€í•œ í¸í–¥ì„ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ì ìš© ë°©ë²•:
        - í¬íŠ¸í´ë¦¬ì˜¤ì— í¬í•¨ëœ ìì‚°ì˜ ìˆ˜ë¥¼ nì´ë¼ê³  í•  ë•Œ, ê° ìì‚°ì˜ ë¹„ì¤‘ì€ 1/nìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        - ì˜ˆë¥¼ ë“¤ì–´, 4ê°œì˜ ìì‚°ì´ ìˆë‹¤ë©´ ê° ìì‚°ì˜ ë¹„ì¤‘ì€ 25%ê°€ ë©ë‹ˆë‹¤.

    2. **Maximum Sharpe Ratio (ìµœëŒ€ ìƒ¤í”„ ë¹„ìœ¨)**
    - ì„¤ëª…: ìƒ¤í”„ ë¹„ìœ¨ì€ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì´ˆê³¼ ìˆ˜ìµë¥ ì„ ë³€ë™ì„±ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµì„ ì¸¡ì •í•©ë‹ˆë‹¤.
    - ì ìš© ë°©ë²•:
        - ì˜ˆìƒ ìˆ˜ìµë¥ (mu)ê³¼ ê³µë¶„ì‚° í–‰ë ¬(S)ì„ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì  í”„ë¡ í‹°ì–´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        - ìƒ¤í”„ ë¹„ìœ¨ì„ ìµœëŒ€í™”í•˜ëŠ” ë¹„ì¤‘ì„ ê³„ì‚°í•˜ì—¬ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

    3. **Minimum Volatility (ìµœì†Œ ë³€ë™ì„±)**
    - ì„¤ëª…: í¬íŠ¸í´ë¦¬ì˜¤ì˜ ë³€ë™ì„±ì„ ìµœì†Œí™”í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ìœ„í—˜ì„ ì¤„ì´ë©´ì„œ ì•ˆì •ì ì¸ ìˆ˜ìµì„ ì¶”êµ¬í•©ë‹ˆë‹¤.
    - ì ìš© ë°©ë²•:
        - ì˜ˆìƒ ìˆ˜ìµë¥ (mu)ê³¼ ê³µë¶„ì‚° í–‰ë ¬(S)ì„ ì‚¬ìš©í•˜ì—¬ ìµœì†Œ ë³€ë™ì„±ì„ ë‹¬ì„±í•˜ëŠ” ìì‚° ë¹„ì¤‘ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        - ë³€ë™ì„±ì´ ê°€ì¥ ë‚®ì€ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

    4. **Risk Parity (ìœ„í—˜ ê· í˜•)**
    - ì„¤ëª…: ê° ìì‚°ì˜ ìœ„í—˜ ê¸°ì—¬ë„ë¥¼ ê· í˜• ìˆê²Œ ì¡°ì •í•˜ì—¬ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬ì„±í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.
    - ì ìš© ë°©ë²•:
        - ê° ìì‚°ì˜ ìœ„í—˜ì„ í‰ê°€í•˜ê³ , ìœ„í—˜ ê¸°ì—¬ë„ê°€ ë™ì¼í•˜ë„ë¡ ë¹„ì¤‘ì„ ì¡°ì •í•©ë‹ˆë‹¤.
        - ë³€ë™ì„±ì´ ë†’ì€ ìì‚°ì˜ ë¹„ì¤‘ì€ ë‚®ì¶”ê³ , ë³€ë™ì„±ì´ ë‚®ì€ ìì‚°ì˜ ë¹„ì¤‘ì€ ë†’ì…ë‹ˆë‹¤.

    5. **Black-Litterman (ë¸”ë™-ë¦¬í„°ë¨¼ ëª¨ë¸)**
    - ì„¤ëª…: ì‹œì¥ì˜ ê¸°ëŒ€ ìˆ˜ìµë¥ ê³¼ ê°œì¸ì˜ ì „ë§ì„ ê²°í•©í•˜ì—¬ ìµœì ì˜ ìì‚° ë¹„ì¤‘ì„ ì°¾ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
    - ì ìš© ë°©ë²•:
        - ì‹œì¥ì˜ ê¸°ëŒ€ ìˆ˜ìµë¥ (mu)ê³¼ ê³µë¶„ì‚° í–‰ë ¬(S)ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸ì˜ ì „ë§ì„ ë°˜ì˜í•œ ë¹„ì¤‘ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        - ê°œì¸ì˜ ê¸°ëŒ€ ìˆ˜ìµë¥  ì¡°ì •ê°’ì„ ì‚¬ìš©í•˜ì—¬ ë¸”ë™-ë¦¬í„°ë¨¼ ëª¨ë¸ì„ í†µí•´ ìµœì ì˜ ë¹„ì¤‘ì„ ë„ì¶œí•©ë‹ˆë‹¤.
    """)
